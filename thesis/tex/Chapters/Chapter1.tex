% Chapter 1

\chapter{Grundlagen}
\label{Chapter1}
In diesem Kapitel werden viele wichtige Grundlagen vorgestellt, die in der ganzen Arbeit an verschiedenen Stellen benötigt werden. Zuerst werden wir im Detail die deterministische Klein-Gordon-Gleichung mit zugehöriger Existenztheorie präsentieren. Um einen numerischen Lösungsansatz für die KGG zu erhalten wird anschließend das Operatorsplitting erläutert und auf die KGG angewandt. Wir werden dazu für das Strang-Splitting Konvergenz zweiter Ordnung bezüglicher der Zeitschrittweite $\tau$ zeigen. Schlussendlich erklären wir die Modellierung der stochastischen Klein-Gordon-Gleichung und bieten eine kurze Wiederholung von benötigten Begriffen aus der Stochastik und Statistik.

\section{Die Klein-Gordon-Gleichung}
Die für diese Arbeit grundlegende Gleichung ist die lineare Klein-Gordon-Gleichung in der Form
\begin{align}
\label{kgg}
\partialdtt{u}(t,x)&=\alpha \Laplace u(t,x) - \beta(x)u(t,x), \: t>0, \, x\in \Torus^d\\
u(0,x)&=u_0(x), \: x\in \Torus^d\\
\partialdt{u}(0,x)&=v_0(x), \: x\in \Torus^d.
\end{align}
Dabei ist $\Laplace$ der Laplace-Operator im Ort $x$, definiert als
\[\Laplace=\partial^2_{x_1}+\dots+\partial^2_{x_d}.\]
Bevor wir Abhängigkeiten von einer Zufallsvariablen hinzufügen, ist es hilfreich, die Gleichung für deterministische Parameter besser zu verstehen. Diese Mühe ist nicht vergebens, da einige numerische Verfahren zur Bestimmung der Lösung der zufallsabhängigen Gleichung stark auf einem robusten und schnellen Löser der deterministischen Gleichung basieren. Dazu seien als Stichworte Monte"=Carlo"=Verfahren und Kollokationsverfahren genannt, die wir im späteren Verlauf genauer betrachten werden.
\subsection{Physikalische Definitionen}
Die KGG ist eine relativistische Feldgleichung, welche die Kinematik von spin-freien Teilchen, wie dem Pion, beschreibt. Auch das 2012 entdeckte Higgs-Boson ist ein spin-freies Teilchen, es ist jedoch noch unklar, ob es wirklich das von dem Standardmodell der Teilchenphysik vorhergesagte Teilchen ist und sich vom Standardmodell beschreiben lässt \autocite{cern2016}.\\
Dabei ist
\begin{itemize}
\item $\Torus=\R/(2\pi\Z)$ der skalierte eindimensionale Torus. Wir werden ab sofort die vereinfachte Darstellung $\Torus^d=(-\pi,\pi)^d$ mit periodischen Randbedingungen verwenden. Diese Skalierung des Torus ermöglicht das direkte Verwenden der schnellen Fourier-Transformation. Eine beliebige andere Skalierung des Torus ist jedoch ohne Beschränkung der Allgemeinheit möglich.
\item $\absolute{u(t,x)}^2$ physikalisch als Ladungsdichte des Teilchens zum Zeitpunkt $t$ und Ort $x$ interpretierbar \autocite{kleingordon2016}. 
\item $\alpha>0$ das Quadrat der Wellengeschwindigkeit.
\item $\beta(x)>0, \forall x\in \Torus^d,$ in der physikalischen Interpretation das Quadrat aus dem Produkt von quadratischer Wellengeschwindigkeit, Masse und inversem \sloppy{planckschem} Wirkungsquantum. Die Abhängigkeit des Potentialteils der KGG vom Ort $x$ ist dabei eine Verallgemeinerung der klassischen Gleichung.
\item die Differentialgleichung im Gegensatz zur physikalischen Darstellung reellwertig. Insbesondere fordern wir, dass $u$, $u_0$ und $v_0$ reellwertig und die Anfangswerte $u_0$ und $v_0$ periodisch in $(-\pi,\pi)^d$ sind.
\end{itemize}

\subsection{Existenztheorie}
\label{chapter:existencetheory}
Um den analytischen Rahmen für die Existenz und Eindeutigkeit von Lösungen der KGG zu schaffen werden wir die Halbgruppentheorie verwenden. Die verwendete Theorie ist übernommen aus \autocite{HundSchnau} und \autocite{EngelNagel}, dort finden sich auch weitere Details und Beweise der verwendeten Theoreme.
\begin{mathdef}
Sei der Raum der beliebig häufig differenzierbaren periodischen Funktionen definiert als
\[C^\infty (\Torus^d)\coloneqq \lbrace v\colon \Torus^d\to\R \mid v \text{ beliebig häufig stetig differenzierbar und periodisch in }[-\pi,\pi]^d\rbrace.\]
Definieren wir zu $v\in C^\infty((-\pi,\pi)^d)$ und $k\in\N_0$ die Sobolev-Norm $\norm{v}_{k,2}$ durch
\[\norm{v}_{k,2}^2\coloneqq \sum_{|m|\le k}\norm{\dxp{v}{m}}_{L^2((-\pi,\pi)^d)}^2,\quad \text{mit }m\in\N_0^d,\, |m|=m_1+\dots + m_d,\]
so erhalten wir bei Verwendung der schwachen Ableitung und mit Vervollständigung die Sobolev-Räume $H^k((-\pi,\pi)^d)$.\\
Wir definieren einen abgeschlossenen Unterraum --und somit einen Banachraum-- des Sobolev-Raums $H^k((-\pi,\pi)^d)$ durch
\begin{align*}H^k(\Torus^d)\coloneqq &\text{ Abschluss von } C^\infty(\Torus^d)\left(\subset C^\infty((-\pi,\pi)^d)\right)\\
&\text{ bezüglich der Norm von } H^k((-\pi,\pi)^d).
\end{align*}
\end{mathdef}
Zunächst definieren wir die benötigte Halbgruppe $S(\cdot)$ und ihren Generator $A$.
\begin{mathdef}
Zu einem Banachraum $R$ heißt die Abbildung $S(\cdot)\colon \R_+\to L(R)$, die einer Zeit $t$ einen beschränken linearen Operator zuordnet, eine Operatorhalbgruppe, wenn
\[S(0)=I,\quad S(t+s)=S(t)S(s)\quad \forall t,s\ge 0.\]
$S(\cdot)$ heißt $C_0$-Halbgruppe bzw. stark stetig, wenn zusätzlich gilt:
\[\forall r\in R\colon S_r(\cdot)\colon \R_+\to R,\: t\mapsto S(t)r \text{ ist stetig}\]
Den Generator $A$ von $S(\cdot)$ erhält man, indem der Definitionsbereich definiert wird als
\[D(A)\coloneqq \lbrace r\in R\mid \text{ der Grenzwert } \lim\limits_{t\to0+}\frac{1}{t}(S(t)r-r)\text { existiert in }R\rbrace\]
und man anschließend für $r\in D(A)$ definiert
\[Ar\coloneqq \lim\limits_{t\to0+}\frac{1}{t}(S(t)r-r).\]
\end{mathdef}
Im folgenden Theorem wird die Verwendung der Halbgruppentheorie zum Erhalten von eindeutigen Lösungen der KGG klar. Inspiriert ist diese Betrachtungsweise durch den endlich dimensionalen Fall, wo $S(t)r=e^{tA}r$ explizit über die Matrixexponentialfunktion gegeben ist. Häufig werden wir für die von $A$ generierte Halbgruppe $S(t)$ entsprechend ebenfalls die Notation $e^{tA}$ verwenden.
\begin{maththeorem}[Vergleiche {\autocite[Proposition 2.8]{HundSchnau}}]
Ist $A$ Generator der $C_0$-Halbgruppe $S(\cdot)$ und $r\in D(A)$, dann ist für alle $t\ge 0\colon \,S(t)r\in D(A)$ und
\[v\colon \R_+\to R,\quad t\mapsto S(t)r\]
die eindeutige Lösung des Cauchy-Problems
\begin{equation}
\begin{split}
v'(t)&=Av(t),\quad t\ge 0\\
v(0)&=r.
\end{split}
\end{equation}
\end{maththeorem}
Formulieren wir unsere KGG als ein Cauchy-Problem obiger Gestalt, so ist also nur noch zu zeigen, dass der Generator eine $C_0$-Halbgruppe generiert.\\
Den Generator $C$ der KGG mit $\alpha>0$ und $\beta\in L^\infty(\Torus^d)$ schreiben wir als Summe von zwei Operatoren:
\[\underbrace{\begin{pmatrix}0 & I\\ \alpha\Laplace -\beta(x) & 0\end{pmatrix}}_{=C}
=\underbrace{\begin{pmatrix}0 & I\\ \alpha\Laplace-I & 0\end{pmatrix}}_{=\widetilde{A}}
+\underbrace{\begin{pmatrix}0 & 0\\ -\beta(x)+I & 0\end{pmatrix}}_{=\widetilde{B}}\]
Wir werden zuerst zeigen, dass $\widetilde{A}$ eine $C_0$-Halbgruppe generiert und verwenden anschließend, dass die Summe mit einer beschränkten Störung $\widetilde{B}$ diese Eigenschaft erhält.\\[0.2cm]
Wir definieren den komplexen Hilbertraum $R=H^1(\Torus^d)\times H^0(\Torus^d)$ mit zugehörigem leicht abgewandelten Skalarprodukt:
\[\langle \begin{pmatrix}v_1\\v_2\end{pmatrix}, \begin{pmatrix}w_1\\w_2\end{pmatrix}\rangle =\int_{[-\pi,\pi]^d}\alpha \nabla v_1\nabla \overline{w_1}+v_1\overline{w_1}+ v_2\overline{w_2}dx\]
Da $\alpha>0$ ist die durch dieses Skalarprodukt induzierte Norm äquivalent zur Standardnorm des Hilbertraums (welche $\alpha=1$ entspricht). Konvergenz bezüglich beider Normen ist dementsprechend äquivalent und der Raum $R$ mit dem definierten Skalarprodukt ist ebenfalls ein Hilbertraum.\\
Die zu $R$ gehörende Norm ist
\[\norm{\begin{pmatrix}v_1\\v_2\end{pmatrix}}^2=\underbrace{\alpha \sum_{i=1}^d\norm{\partial_{x_i} v_1}^2_{L^2}+\norm{v_1}_{L^2}^2}_{\eqqcolon\norm{v_1}^2_{H^1_\alpha}}+\norm{v_2}_{L^2}.\]
Es ist $D(\widetilde{A})=H^2(\Torus^d)\times H^1(\Torus^d)\subset R$ dicht in $R$, da bereits $C^\infty(\Torus^d)\times C^\infty(\Torus^d)\subset D(\widetilde{A})$ dicht in $R$ ist.\\
Stones Theorem besagt, dass $\widetilde{A}$ genau dann eine $C_0$-Halbgruppe von unitären Operatoren generiert, wenn $\widetilde{A}$ schiefadjungiert bezüglich des Skalarprodukts des Hilbertraums ist. Wir rechnen für $(v_1,v_2)^T, (w_1,w_2)^T\in D(\widetilde{A})$ die Antisymmetrie des Operators $\widetilde{A}$ nach:
\begin{align*}
\langle \widetilde{A}\begin{pmatrix}v_1\\v_2\end{pmatrix}, \begin{pmatrix}w_1\\w_2\end{pmatrix}\rangle
&=\langle \begin{pmatrix} v_2\\\alpha \Laplace v_1-v_1\end{pmatrix}, \begin{pmatrix}w_1\\w_2\end{pmatrix}\rangle\\
&=\int_{[-\pi,\pi]^d} \alpha \nabla v_2\nabla \overline{w_1} +v_2\overline{w_1}+ \alpha \Laplace v_1 \overline{w_2} - v_1\overline{w_2}dx\\
&\stackrel{(*)}{=}-\int_{[-\pi,\pi]^d}\alpha v_2\Laplace \overline{w_1}-v_2\overline{w_1}+ \alpha \nabla v_1\nabla \overline{w_2} + v_1\overline{w_2}dx\\
&=-\langle \begin{pmatrix} v_1\\ v_2\end{pmatrix}, \begin{pmatrix} w_2\\\alpha \Laplace w_1-w_1\end{pmatrix}\rangle=-\langle \begin{pmatrix}v_1\\v_2\end{pmatrix}, \widetilde{A}\begin{pmatrix}w_1\\w_2\end{pmatrix}\rangle
\end{align*}
Die Identität $(*)$ folgt mit Green, da $v_1,v_2,w_1,w_2$ periodisch sind.\\
Wäre $\widetilde{A}$ beschränkt, so folgt daraus sofort die Schiefadjungiertheit $\widetilde{A}=-\widetilde{A}^*$ von $\widetilde{A}$. Da in unserem Fall $\widetilde{A}$ unbeschränkt ist, müssen wir zusätzlich die Bedingung $D(\widetilde{A})=D(\widetilde{A}^*)$ erfüllen.\\
Wir benutzen die Eigenschaft:
\[\widetilde{A} \text{ schiefadjungiert } \equivalent i\widetilde{A} \text{ selbstadjungiert}\]
Nach \autocite[Bemerkung 5.6f]{HundSchnau} müssen wir für die Selbstadjungiertheit von $i\widetilde{A}$ folgende Bedingungen erfüllen:
\begin{itemize}
\item $i\widetilde{A}$ symmetrisch
\item $i\widetilde{A}$ abgeschlossen, d.h. für $\lbrace u_n \rbrace \in D(\widetilde{A})$ mit $u_n\to u\in R$ und $\widetilde{A}u_n\to y\in R$ für $n\to\infty$ gilt: $u\in D(\widetilde{A})$ und $\widetilde{A}u=y$.
\item $\sigma(i\widetilde{A})\subset \R$
\end{itemize}
Die Symmetrie von $i\widetilde{A}$ ist äquivalent zur bereits gezeigten Antisymmetrie von $\widetilde{A}$.\\
Die Abgeschlossenheit von $i\widetilde{A}$ ist äquivalent zur Abgeschlossenheit von $\widetilde{A}$. Sei dazu $u_n\in D(\widetilde{A})$, $u_n\xrightarrow{n \to \infty }u\in R$ und $Au_n\xrightarrow{n \to \infty }y\in R$, also:
\begin{align*}
u_n=\begin{pmatrix}u_{1,n}\\u_{2,n}\end{pmatrix}\to\begin{pmatrix}u_1\\u_2\end{pmatrix}\in H^1(\Torus^d)\times L^2(\Torus^d)\\
\widetilde{A}\begin{pmatrix}u_{1,n}\\u_{2,n}\end{pmatrix}=\begin{pmatrix}u_{2,n}\\\alpha\Laplace u_{1,n}-u_{1,n}\end{pmatrix}\to\begin{pmatrix}y_1\\y_2\end{pmatrix}\in H^1(\Torus^d)\times L^2(\Torus^d).
\end{align*} 
Somit gilt $u_{2,n}\to u_2$ in $L^2(\Torus^d)$ und $u_{2,n}\to y_1$ in $H^1(\Torus^d)$ woraus sofort $u_2=y_1\in H^1(\Torus^d)$ folgt.\\
Entsprechend gilt $u_{1,n}\to u_1$ in $H^1(\Torus^d)$. Um $u_1\in H^2(\Torus^d)$ zu erhalten und somit $u\in D(A)$, ist in diesem Fall noch einzusehen, dass die zweiten Ableitungen von $u_1$ nach $x$ existieren und in $L^2(\Torus^d)$ sind. Dies ist erfüllt wegen $\alpha \Laplace u_{1,n}-u_{1,n}\to y_2$ in $L^2(\Torus^d)$.\\
Somit gilt $u\in D(\widetilde{A})$ und wegen 
\begin{align*}
\norm{\widetilde{A}u-y}&\le \norm{\widetilde{A}u-\widetilde{A}u_n}+\norm{\widetilde{A}u_n-y}\\
&=\norm{\begin{pmatrix}u_2-u_{2,n}\\\Laplace(u_1-u_{1,n})-(u_1-u_{1,n})\end{pmatrix}}+\norm{\widetilde{A}u_n-y}\\
&\le \norm{u_2-u_{2,n}}_{H^1}+\norm{\Laplace(u_1-u_{1,n})}_{L^2}+\norm{u_1-u_{1,n}}_{L^2}+\norm{\widetilde{A}u_n-y}\xrightarrow{n \to \infty }0
\end{align*}
ist $\widetilde{A}u=y$ und $\widetilde{A}$ somit abgeschlossen.\\
Für die Bedingung $\sigma(i\widetilde{A})\subset \R$ sei $\lambda \in\Complex\setminus\R$. Zu zeigen ist $\lambda \in\rho(i\widetilde{A})$, der Resolventenmenge von $i\widetilde{A}$. Sei dazu
\[f=\begin{pmatrix}f_1\\f_2\end{pmatrix}\in H^1(\Torus^d)\times L^2(\Torus^d)\]
und ein $u\in D(\widetilde{A})$ gesucht welches $(i\widetilde{A}-\lambda I)u=f$ erfüllt.\\
Nachrechnen ergibt:
\begin{align*}
iu_2-\lambda u_1=f_1 &\implies u_2=(f_1+\lambda u_1)(-i)\\
i\alpha \Laplace u_1-iu_1-\lambda u_2=f_2 &\implies i\alpha \Laplace u_1-iu_1+i\lambda f_1+i\lambda^2u_1=f_2\\
&\quad \equivalent \alpha \Laplace u_1-u_1+\lambda^2u_1=-if_2-\lambda f_1\eqqcolon g
\end{align*}
Aus dem Ansatz $u_1(x)=\sum_{k\in\Z}\fourier{u}_ke^{ikx}$ (beispielhaft für $d=1$) folgt
\[\sum_{k\in\Z}\fourier{u}_k(\alpha (ik)^2-1+\lambda^2)e^{ikx}=\sum_{k\in\Z}\fourier{g}_ke^{ikx}.\]
Und somit ist $\fourier{u}_k=\frac{\fourier{g}_k}{-\alpha k^2-1+\lambda^2}$ eine gültige Wahl für die Fourier-Koeffizienten, da 
\[-\alpha k^2-1+\lambda^2=0\equivalent \lambda =\pm \sqrt{k^2+1}\in\R.\]
Die Gleichung $(i\widetilde{A}-\lambda I)u=f$ besitzt somit eine Lösung $u\in D(\widetilde{A})$ und daher gilt $\lambda \in \rho(i\widetilde{A})$ und schlussendlich $\sigma(i\widetilde{A})\subset \R$.\\
Insgesamt ist nun $i\widetilde{A}$ selbstadjungiert, daher ist $\widetilde{A}$ schiefadjungiert und nach Stone erzeugt $(\widetilde{A},D(\widetilde{A}))$ eine unitäre Halbgruppe.\\[0.3cm] 
Um den vollen Generator $C$ der KGG zu erhalten benötigen wir noch den zweiten Teiloperator $\widetilde{B}$ definiert durch
\[\widetilde{B}=\begin{pmatrix}0 & 0\\-\beta(x)+I & 0\end{pmatrix}.\]
Dazu verwenden wir das Theorem über beschränkte Störungen eines stark stetigen Generators.
\begin{maththeorem}[{\autocite[Theorem 1.3, Kapitel III]{EngelNagel}}]
\label{th:engelnagelbounded}
Ist $A$ Generator einer stark stetigen Halbgruppe $S(\cdot)$ mit Definitionsbereich $D(A)$ auf einem Banachraum $R$ und $B\colon R\to R$ ein beschränkter linearer Operator, so ist
$C=A+B$ mit $D(C)\coloneqq D(A)$ ebenfalls Generator einer stark stetigen Halbgruppe $\widetilde{S}(\cdot)$.\\
Gibt es ein $M\ge 1$ und $w\in\R$ mit
\[\norm{S(t)}\le Me^{wt},\quad \text{ für alle } t\ge 0,\]
so gilt
\[\norm{\widetilde{S}(t)}\le Me^{(w+M\norm{B})t},\quad \text{ für alle } t\ge 0.\]
\end{maththeorem}Die Beschränktheit von $\widetilde{B}$ ist direkt gezeigt:\\
Es gilt für $\beta\in L^2(\Torus^d)\cap L^\infty(\Torus^d)$
\begin{align*}
\norm{\widetilde{B}\begin{pmatrix}v_1\\v_2\end{pmatrix}}^2&=\norm{\begin{pmatrix}0\\v_1-\beta(x)v_1\end{pmatrix}}^2\\
&\le c\norm{v_1}_{L^2}^2, \quad c=(\norm{\beta}_{\infty}+1)^2\\
&\le c\norm{\begin{pmatrix}v_1\\v_2\end{pmatrix}}^2.
\end{align*}
Insgesamt ist somit der definierende Operator 
\[C=\begin{pmatrix}0 & I\\ \alpha\Laplace - \beta(x) & 0\end{pmatrix}\]
der Klein-Gordon-Gleichung Generator einer $C_0$-Halbgruppe und das zugehörige Cauchy-Problem besitzt eine eindeutige Lösung in $D(\widetilde{A})$. Dies impliziert auch eine eindeutige Lösung der KGG in $H^2(\Torus^d)$.
\subsubsection*{Abschätzungen für die generierten Halbgruppen}
Da $\widetilde{A}$ eine unitäre Halbgruppe generiert und der Operator 
\[\widetilde{I}=\begin{pmatrix}0&0\\I&0\end{pmatrix}\]
beschränkt mit $\norm{\widetilde{I}}=1$ ist, gilt nach Satz \ref{th:engelnagelbounded} für die von $\widetilde{A}+\widetilde{I}$ erzeugte Halbgruppe
\begin{equation}
\label{eqn:normgroupofa}
\norm{\exp\left(t(\widetilde{A}+\widetilde{I})\right)}=\norm{\exp\left(t\begin{pmatrix}0 & I\\\alpha\Laplace & 0\end{pmatrix}\right)}\le e^t,\quad t\ge 0.
\end{equation}
Für die von $\widetilde{B}-\widetilde{I}$ erzeugte Halbgruppe gilt
\begin{equation}
\label{eqn:normgroupofb}
\norm{\exp\left(t(\widetilde{B}-\widetilde{I}\right)}=\norm{\exp\left(t\begin{pmatrix}0 & 0\\ -\beta & 0\end{pmatrix}\right)}=\norm{\begin{pmatrix}I & 0\\-t\beta & I\end{pmatrix}}\le 1+\norm{\beta}_\infty t.
\end{equation}
\begin{proof}[Beweis der Ungleichung (\ref{eqn:normgroupofb})]
Sei $v=\begin{pmatrix}v_1\\v_2\end{pmatrix}\in H^1\times L^2$. Es gilt
\begin{align*}
\norm{\begin{pmatrix}I & 0\\-t\beta & I\end{pmatrix}\begin{pmatrix}v_1\\v_2\end{pmatrix}}^2
&=\norm{\begin{pmatrix}v_1\\v_2-t\beta v_1\end{pmatrix}}^2=\norm{v_1}_{H^1_\alpha}^2+\norm{v_2-t\beta v_1}_{L^2}^2\\
&\le \norm{v_1}_{H^1_\alpha}^2+\left(\norm{v_2}_{L^2}+t\underbrace{\norm{\beta v_1}_{L^2}}_{\le \norm{\beta}_\infty\norm{v_1}_{L^2}}\right)^2\\
&\le \underbrace{\norm{v_1}_{H^1_\alpha}^2 + \norm{v_2}_{L^2}^2}_{=\norm{v}^2} + 2t\norm{\beta}_\infty \underbrace{\norm{v_1}_{L^2}\norm{v_2}_{L^2}}_{\le \onehalf \left(\norm{v_1}_{L^2}^2+\norm{v_2}_{L^2}^2\right)\le \norm{v}^2} + t^2\norm{\beta}_\infty^2\norm{v_1}_{L^2}^2\\
&\le (1+t\norm{\beta}_\infty)^2\norm{v}^2.
\end{align*}
\end{proof}
Die Teilung des Generators $C$ der KGG wird nicht nur ein Werkzeug für die theoretische Existenztheorie bleiben, sondern die Grundlage für eine numerische Herangehensweise zur Berechnung von Approximationen der Lösung werden. Die gezeigten Abschätzungen bilden dabei die Basis für Konvergenzaussagen dieses \emph{Operatorsplittings}.
\subsection{Exakte Lösungen}
Für spezielle Konfigurationen der Parameter und Anfangswerte können wir exakte Lösungen angeben. Diese sind hilfreich, um die Korrektheit von Implementierungen schnell und zuverlässig testen zu können. Außerdem werden so schnell die Grenzen und eventuelle Schwächen der Verfahren für gut gestellte Probleme deutlich.\\[0.5cm]
Mithilfe des Separationsansatzes $u(t,x)=g(x)f(t)$ erhalten wir aus (\ref{kgg}) die Darstellung
\begin{equation*}
(\alpha\Laplace g(x)-\beta(x)g(x))f(t) = g(x)f''(t).
\end{equation*}
Diese können wir trennen und bekommen die zwei Differentialgleichungen
\begin{align*}
\alpha\Laplace g(x)-\beta(x)g(x)&=\lambda g(x), \: \lambda\in\R\\
\mu f(t)&=f''(t), \: \mu\in \R.
\end{align*}
Für $\beta(x) \equiv \beta>0$ ergibt sich das Eigenwertproblem $-\Laplace g(x)=-\frac{\beta + \lambda}{\alpha}g(x)$ mit periodischen Randbedingungen und eine lineare gewöhnliche Differentialgleichung.\\
Schlussendlich gewinnen wir daraus Lösungen für die ursprüngliche KGG. Die Anfangswerte $u_0$ und $v_0$ der KGG werden dann entsprechend passend gewählt.\\[1cm]
Beispiele für exakte Lösungen ($d=1$) sind
\begin{align*}
u(t,x)&=\sin(\lambda x)(c_1 \sin(\mu t) + c_2 \cos(\mu t)), \quad \mu^2=\beta+\alpha \lambda^2,\quad \beta(x)\equiv \text{const}\\ 
u(t,x)&=(c_1 \sin(\lambda x) + c_2 \cos(\lambda x))\sin(\mu t), \quad \mu^2=\beta+\alpha \lambda^2,\quad \beta(x)\equiv \text{const}\\
u(t,x)&=\exp(-\cos(x))\sin(\mu t), \quad \beta(x)=\mu^2+\cos(x)+\sin^2(x), \, \mu \in \R,
\end{align*}
wobei $\lambda\in \pi\Z$ um die Periodizität zu gewährleisten und $c_1, c_2 \in \R$ frei wählbare Skalierungsfaktoren sind.\\
Diese Lösungen lassen sich auch auf höhere Dimensionen erweitern, beispielsweise
\begin{eqnarray}
u(t,x)=\exp(-\cos(x_1+\dots+x_d))\sin(\mu t)\\
\beta(x)=\mu^2+d(\cos(x_1+\dots+x_d)+\sin^2(x_1+\dots+x_d)), \, \mu\in\R. \nonumber
\end{eqnarray}
Um einen kleinen Einblick in die Gestalt einer einfachen expliziten Lösung der KGG zu erhalten, sind in Abbildung \ref{fig:exactsolonedim} und \ref{fig:exactsoltwodim} die Lösungen mit Parametern $\alpha=1$, $\beta(x)=4+d(\cos(\sum_{j=1}^dx_j)+\sin^2(\sum_{j=1}^dx_j))$ zum Zeitpunkt $t=0.5$ dargestellt.
% Visualize exact solutions by giving two example plots
\begin{figure}[!htb]
\minipage{0.5\textwidth}
  \includegraphics[width=\linewidth]{Figures/kgg_exact_solution_example1d.png}
  \caption{Exakte Lösung für $d=1$}
  \label{fig:exactsolonedim}
\endminipage
\minipage{0.5\textwidth}
  \includegraphics[width=\linewidth]{Figures/kgg_exact_solution_example2d.png}
  \caption{Exakte Lösung für $d=2$}
  \label{fig:exactsoltwodim}
\endminipage
\captionsetup{labelformat=empty}
\end{figure}

Eine Sammlung von nicht-periodischen Lösungen finden sich in \autocite{andreipolyanin2004}.

\section{Operatorsplitting}
Als numerischen Ansatz für approximative Lösungen der KGG wählen wir ein klassisches Operatorsplitting. Dabei wiederholen wir an dieser Stelle zuerst kurz die relevante Approximationstheorie und diskutieren mögliche Varianten.
\subsection{Grundlegende Idee}
Angenommen, wir stehen vor dem Problem die Differentialgleichung 
\begin{equation}
\label{gencompdgl}
\dt{u}(t)=(L+R)u(t), \, t>0, \quad u(0)=u_0
\end{equation}
lösen zu wollen. Dabei ist im einfachsten Fall $u$ eine vektorwertige Funktion und $L$ bzw. $R$ zwei Matrizen.\\
Ist beispielsweise $L=Q\Lambda Q^T$ eine einfach zu diagonalisierende Matrix und $R$ eine Diagonalmatrix, so sind die entkoppelten Gleichungen 
\begin{align*}
\dt{(Q^Tv)}(t)&=\Lambda Q^Tv(t), \quad v(0)=v_0\\
\dt{w}(t)&=Rw(t), \quad w(0)=w_0
\end{align*}
einfacher zu lösen als die Gleichung (\ref{gencompdgl}). Das Ziel des Operatorsplittings ist es, aus den Lösungen $v$ und $w$ eine Approximation an $u$ zu gewinnen.\\
Wir \emph{teilen} (engl. split) die Gleichung also in zwei neue Gleichungen auf. Häufig lässt sich dann eine der gewonnen Gleichungen sogar exakt lösen. Dieser Ansatz funktioniert auch für (nicht-lineare) Operatoren anstelle von Matrizen.\\
Diese zentrale Idee werden wir verwenden, um die KGG 
\begin{equation*}
\partialdtt{u}(t,x)=\alpha\Laplace u(t,x)-\beta(x)u(t,x)
\end{equation*}
zu splitten. Dabei wird der Operator $\alpha\Laplace$ in $L$ einfließen und $-\beta(x)$ in $R$. Man beachte jedoch, dass die zeitliche Ableitung zweiter Ordnung von $u$ eine Umschreibung in ein System erster Ordnung erfordert, bevor ein Splittingansatz sinnvoll ist.

\subsection{Lie-Trotter-Splitting}
\label{seclietrotter}
Wir beginnen mit einer rigorosen Einführung in Splittingverfahren. Als zentrales Ergebnis werden wir dabei das Strang-Splitting erhalten, welches einen Fehler $\mathcal{O}(\deltat^2)$ in Abhängigkeit von der Zeitschrittweite $\deltat$ besitzt.\\
Die folgende Einführung ist angelehnt an \autocite[Kapitel II.3 bis II.5]{HairerLubichWanner}.
\begin{mathdef}[Fluss einer Differentialgleichung]
Der Fluss $\varphi_t$ einer reversiblen Differentialgleichung
\begin{equation}
\label{orddgl}
\dt{y}=f(y),\quad y(0)\:\text{ gegeben}
\end{equation}
mit $f\colon \R^d\to\R^d$ ist die injektive Abbildung, die einem gegebenen $y_0$ die exakte Lösung $y(t)$ zum Zeitpunkt $t$ mit Anfangsbedingung $y(0)=y_0$ zuordnet. Also gilt
\begin{equation*}
\varphi_t(y_0)=y(t)\enspace und\enspace y(0)=y_0.
\end{equation*}
\end{mathdef}

Um Splittingverfahren von möglichst höher Ordnung zu bekommen ist es wichtig, die einzelnen Teilverfahren bestmöglich zu kombinieren. Hierbei spielt das adjungierte Verfahren eine wichtige Rolle, da es dabei hilft, symmetrisierte Verfahren mit gerader Ordnung zu gewinnen.
\begin{mathdef}[Adjungiertes Verfahren]
Ist $\Phi_{\deltat}\colon\R^d\to\R^d$ ein Einschrittverfahren so definieren wir das adjungierte Verfahren $\Phi_{\deltat}^*$ als das Inverse des Einschrittverfahrens mit negativer Schrittweite $\deltat$, also \[\Phi_{\deltat}^*\coloneqq\Phi_{-\deltat}^{-1}.\]
Das bedeutet, dass $y_1=\Phi_{\deltat}^*(y_0)$ implizit durch $\Phi_{-\deltat}(y_1)=y_0$ definiert wird.\\
Ist $\Phi_{\deltat}^*=\Phi_{\deltat}$ so nennen wir das Verfahren symmetrisch.
\end{mathdef}
Beispielsweise sind das explizite Euler-Verfahren $\Phi_{\deltat}^E$ und das implizite Euler-Verfahren $\Phi_{\deltat}^{IE}$ zueinander adjungiert: 
\[\Phi_{-\deltat}^E(y_1)=y_0\implies y_1+(-\deltat)f(y_1)=y_0\implies y_1=y_0+\deltat f(y_1)=\Phi_{\deltat}^{IE}(y_0)\] \\
Ohne Beweis sei bemerkt, dass $(\Phi_{\deltat}^*)^*=\Phi_{\deltat}$ und 
\begin{equation}
\label{adjlemma}
(\Phi_{\deltat}\circ \Psi_{\deltat})^*=\Psi_{\deltat}^* \circ \Phi_{\deltat}^*.
\end{equation}

\begin{mathdef}[Konsistenzordnung]
Eine numerische Methode zum Lösen von (\ref{orddgl}) ist (konsistent) von Ordnung $p$, wenn der lokale Fehler für hinreichend glattes $y$
\[\Phi_{\deltat}(y(t))=\varphi_{\deltat}(y(t))+\mathcal{O}(\deltat^{p+1})\] erfüllt.
\end{mathdef}
\begin{maththeorem}[Ordnung des adjungierten Verfahrens, vgl. 
{\autocite[Theorem II.3.2]{HairerLubichWanner}}]
\label{adjfloworder}
Sei $\varphi_t$ der exakte Fluss von (\ref{orddgl}) und sei $\Phi_{\deltat}$ ein Einschrittverfahren von Ordnung $p$ welches 
\[\Phi_{\deltat}(y_0)=\varphi_{\deltat}(y_0)+C(y_0)\deltat^{p+1}+\mathcal{O}(\deltat^{p+2})\]
erfüllt. Dann ist das adjungierte Verfahren $\Phi_{\deltat}^*$ ebenfalls von Ordnung $p$ und erfüllt
\[\Phi_{\deltat}^*(y_0)=\varphi_{\deltat}(y_0)+(-1)^{p}C(y_0)\deltat^{p+1}+\mathcal{O}(\deltat^{p+2})\]
Ist insbesondere $\Phi_{\deltat}$ symmetrisch, so ist wegen $C(y_0)=(-1)^pC(y_0)$ die Ordnung $p$ gerade.
\end{maththeorem}
Nun zerlegen wir die ursprüngliche Gleichung (\ref{orddgl}) in zwei Teile:
\[\dt{y}=f(y)=A(y)+B(y) \]
Das Aufteilen ist hierbei nicht eindeutig! Eine Möglichkeit im zweidimensionalen wäre zum Beispiel: $A=\text{P}_{(1,0)^T}f,\,B=\text{P}_{(0,1)^T}f$, wobei $\text{P}_v$ die Projektion auf $\text{span}(v)$ darstellt. Wie in unserem Fall der KGG ist die bereits vorhandene natürliche Aufteilung der Summe die Methode der Wahl.\\
Sind nun $\varphi_{\deltat}^A$ und $\varphi_{\deltat}^B$ die exakten Flüsse der Systeme
\begin{align}
\dt{y}&=A(y)\quad \text{und} \label{splitsimple1}\\ 
\dt{y}&=B(y) \label{splitsimple2}
\end{align}
so gewinnen wir daraus ein Verfahren zur Lösung der ursprünglichen Gleichung.\\
Hierzu starten wir von einem gegebenen Anfangswert $y_0$ und lösen das System (\ref{splitsimple1}) um einen Zwischenwert $y_{\onehalf}$ zu erhalten. Verwenden wir diesen als neuen Startwert für das System (\ref{splitsimple2}), so erhalten wir daraus einen Wert $y_1$, welcher eine Approximation an die Lösung $\varphi_{\deltat}(y_0)$ des ursprünglichen Systems ist.\\[1cm]
\noindent\begin{minipage}{0.3\textwidth}
\input{tikz/splitting_lie_flow}
\input{tikz/splitting_lie_flow_adj}
\end{minipage}%
\hfill%
\begin{minipage}{0.7\textwidth}
Die Reihenfolge $A\to B$ ist willkürlich und kann auch umgekehrt werden. Tatsächlich sind die resultierenden Verfahren aufgrund von (\ref{adjlemma}) zueinander adjungiert, da der exakte Fluss wegen $y_1=\varphi_{-\deltat}^{-1}(y_0)=\varphi_{\deltat}^*(y_0)=\varphi_{\deltat}(y_0)$ als symmetrisches Einschrittverfahren auffassbar ist. Kurz:\\
\begin{align}
\label{liesplittings}
\Phi_{\deltat}=\varphi_{\deltat}^B \circ \varphi_{\deltat}^A\\
\Phi_{\deltat}^*=\varphi_{\deltat}^A \circ \varphi_{\deltat}^B\nonumber
\end{align} 
\end{minipage}

\begin{maththeorem}[Ordnung des Lie-Trotter-Splittings]
\label{lieorder1}
Das Lie-Trotter-Splitting $\Phi_{\deltat}=\varphi_{\deltat}^B \circ \varphi_{\deltat}^A$ und sein adjungiertes $\Phi_{\deltat}^*=\varphi_{\deltat}^A \circ \varphi_{\deltat}^B$ sind von Ordnung $p=1$.
\end{maththeorem}
\begin{proof}
Die Taylorreihe von $\varphi_{\deltat}$ lässt sich wegen 
\[\varphi_{\deltat}(y_0)=y(\deltat)=y(0)+\deltat \underbrace{y^\prime(0)}_{=f(y_0)}
+\frac{\deltat^2}{2}\underbrace{y^{\prime\prime}(0)}_{=f^\prime(y_0)y^\prime(0)=f^\prime(y_0)f(y_0)}+\mathcal{O}(\deltat^3)\] darstellen als 
\[\varphi_{\deltat}(y_0)=y_0+\deltat f(y_0)+\frac{\deltat^2}{2}f^\prime(y_0)f(y_0)+\mathcal{O}(\deltat^3).\]
Diese vergleichen wir nun mit der Taylorreihe des Splittings:
\begin{align*}
\left(\varphi_{\deltat}^B \circ \varphi_{\deltat}^A\right)(y_0)&=
\varphi_{\deltat}^B\left(y_0+\deltat f^A(y_0)+\frac{\deltat^2}{2}f^{\prime A}(y_0)f^A(y_0)+\mathcal{O}(\deltat^3)\right)\\
&=\left(y_0+\deltat f^A(y_0)+\frac{\deltat^2}{2}f^{\prime A}(y_0)f^A(y_0)\right)
+\deltat f^B\left(y_0+\deltat f^A(y_0)+\mathcal{O}(\deltat^2)\right)\\
&\quad+\frac{\deltat^2}{2}f^{\prime B}\left(y_0+\mathcal{O}(\deltat)\right)f^B\left(y_0+\mathcal{O}(\deltat)\right)+\mathcal{O}(\deltat^3)\\
&=y_0+\deltat f(y_0)+\frac{\deltat^2}{2}f^\prime(y_0)f(y_0)\\
&\quad+\frac{\deltat^2}{2}\left(f^{\prime B}(y_0)f^A(y_0)-f^{\prime A}(y_0)f^B(y_0)\right)+\mathcal{O}(\deltat^3)
\end{align*}
So erhalten wir für hinreichend glatte Funktionen $f^A$, $f^{\prime A}$, $f^B$ und $f^{\prime B}$ den Fehler \[\varphi_{\deltat}(y_0)-\left(\varphi_{\deltat}^B \circ \varphi_{\deltat}^A\right)(y_0)=\mathcal{O}(\deltat^2)\] und die Ordnung $p=1$. Mit Satz \ref{adjfloworder} ist das adjungierte Verfahren ebenfalls von Ordnung $p=1$.
\end{proof}

\subsection{Strang-Splitting}
\label{secstrang}
Durch geschicktes Kombinieren der Einschrittverfahren $\Phi_{\deltat}$ und $\Phi_{\deltat}^*$ mit verschiedenen Schrittweiten lassen sich Splittingverfahren beliebiger Ordnung konstruieren.
\begin{maththeorem}[vgl. {\autocite[Theorem II.4.1ff]{HairerLubichWanner}}]
Ist $\Phi_{\deltat}$ ein Einschrittverfahren von Ordnung $p$ so ist die Zerlegung
\[\Psi_{\deltat}=\Phi_{a_s\deltat}\circ \Phi_{b_s\deltat}^*\circ\dots\circ\Phi_{b_2\deltat}^*\circ\Phi_{a_1\deltat}\circ\Phi_{b_1\deltat}^*\]
von Ordnung $p+1$, wenn 
\begin{align*}
\sum_{j=1}^sa_j+b_j&=1\\
\sum_{j=1}^sa_j^{p+1}+(-1)^pb_j^{p+1}&=0.
\end{align*}
\end{maththeorem}
Um das Lie-Trotter-Splitting zur Ordnung 2 zu erweitern motiviert der Satz die Wahl $\alpha_1=\beta_1=\onehalf$. Wir wollen nun ein Verfahren $\Phi_{\deltat}^S$ mit Ordnung $p=2$ gewinnen. Daher definieren wir
\[\Phi_{\deltat}^S=\Phi_{\deltathalf}^*\circ\Phi_{\deltathalf}=\left(\Phi_{\deltat}^S\right)^*.\]
Wir erkennen sofort, dass es sich hierbei um ein symmetrisches Verfahren handelt. Als Komposition von Verfahren mit Ordnung 1 (siehe Satz \ref{lieorder1}) ist es ebenfalls mindestens von Ordnung 1. Als zusätzlich symmetrisches Verfahren gilt mit Satz \ref{adjfloworder}, dass das Verfahren mindestens von Ordnung 2 ist.\\
Dieses sogenannte \emph{Strang-Splitting} lässt sich unter Verwendung der aufgeteilten Flüsse (\ref{liesplittings}) auch darstellen als 

\noindent\begin{minipage}{0.3\textwidth}
\input{tikz/splitting_strang_flow}
\end{minipage}%
\hfill%
\begin{minipage}{0.7\textwidth}
\begin{align}
\Phi_{\deltat}^S&=\varphi_{\deltathalf}^A\circ\varphi_{\deltathalf}^B\circ\varphi_{\deltathalf}^B\circ\varphi_{\deltathalf}^A\nonumber\\
&=\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ\varphi_{\deltathalf}^A
\end{align}
\end{minipage}
Für einen Schritt des Verfahrens ist wegen der Zusammenfassung der zwei inneren Teilschritte $\varphi_{\deltathalf}^B$ ist im Vergleich zum Lie-Trotter-Splitting also nur der anderthalbfache Aufwand nötig, aber man gewinnt bereits eine Ordnung dazu. Die Laufzeit kann sogar noch verbessert werden:\\
Gegeben sei ein Anfangswert $y_0$ für das System (\ref{orddgl}). Ist man an einer Approximation $y_T$ der Lösung $y(T)$ zu einem Zeitpunkt $T=n\deltat>0$ interessiert, so gilt unter Verwendung des Strang-Splittingverfahrens
\begin{align*}
y_T&=\underbrace{\Phi_{\deltat}^S\circ\dots\circ\Phi_{\deltat}^S}_{n\text{ mal}}(y_0)\\
&=\left(\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ\varphi_{\deltathalf}^A\right)\circ\left(
\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ\varphi_{\deltathalf}^A\right)\circ\dots\circ\left(
\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ\varphi_{\deltathalf}^A\right)\\
&=\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ\left(\varphi_{\deltat}^A\circ\varphi_{\deltat}^B\right)\circ\left(\varphi_{\deltat}^A\circ\varphi_{\deltat}^B\right)\circ\dots\circ\left(\varphi_{\deltat}^A\circ\varphi_{\deltat}^B\right)\circ\varphi_{\deltathalf}^A\\
&=\varphi_{\deltathalf}^A\circ\varphi_{\deltat}^B\circ
\underbrace{\Phi_{\deltat}^*\circ\dots\circ\Phi_{\deltat}^*}_{n-1\text{ mal}}\circ\,\varphi_{\deltathalf}^A.
\end{align*}
Durch das Kombinieren der äußeren Halbschritte bekommt man somit eine Darstellung des Strang-Splittings, die im Vergleich zum Lie-Trotter-Splitting nur einen zusätzlichen Fluss berechnen muss und trotzdem Ordnung $p=2$ besitzt. Man muss hierbei allerdings auf Zwischenergebnisse verzichten, da diese eine weitere Anwendung von $\varphi_{\deltathalf}^A$ benötigen würden.\\[0.5cm]
Bisher sind wir davon ausgegangen, dass sich die Flüsse $\varphi_{\deltat}^A$ btw. $\varphi_{\deltat}^B$ exakt berechnen lassen. Dies ist in den seltensten Fällen der Fall und man verwendet stattdessen approximative Verfahren $\Phi_{\deltat}^A$ bzw. $\Phi_{\deltat}^B$. 
\begin{maththeorem}
Falls
\begin{align*}
\Phi_{\deltat}^A(y(t))=\varphi_{\deltat}^A(y(t))+\mathcal{O}(\deltat^{p+1})\\
\Phi_{\deltat}^B(y(t))=\varphi_{\deltat}^B(y(t))+\mathcal{O}(\deltat^{p+1}),
\end{align*}
so gelten Satz \ref{adjfloworder}, Satz \ref{lieorder1} und alle entsprechenden Aussagen aus Kapitel \ref{seclietrotter} und Kapitel \ref{secstrang} für $\Phi_{\deltat}^A$ und $\Phi_{\deltat}^B$ anstelle von $\varphi_{\deltat}^A$ und $\varphi_{\deltat}^B$.\\
Insbesondere ist das Strang-Splitting immer noch von Ordnung 2, wenn alle verwendeten Approximationen von Ordnung 2 sind.
\end{maththeorem}
\begin{proof}[Beweisidee]
Am Beispiel von $\varphi_{\deltat}^A$ und $p=1$:\\
Man verwendet die Darstellung $\varphi_{\deltat}^A(y_0)=y_0+\deltat f^A(y_0)+\mathcal{O}(\deltat^2)$ und ersetzt $\varphi_{\deltat}^A$ durch $\Phi_{\deltat}^A$. Die Vorgehensweise in den Beweisen benötigt dann minimale Anpassungen.\\
Man beachte hierbei, dass nun $\Phi_{\deltat}^A$ im Gegensatz zu $\varphi_{\deltat}^A$ nicht mehr symmetrisch ist. Die Argumentation über die Ordnung von symmetrischen Verfahren kann daher nicht direkt verwendet werden, um $p=2$ für das Strang-Splittings zu begründen. Außerdem kann dies die Möglichkeit, das Strang-Splitting durch Kombination der Halbschritte zu beschleunigen, zunichte machen.
\end{proof}
\subsection{Konvergenzordnung des Operatorsplittings}
Die bisherigen Erläuterungen beziehen sich auf die klassische Ordnung der Splitting Varianten. Sie benötigen hinreichend glatte Lösungen, welche im Fall der KGG und dem unbeschränkten Operator 
\[\begin{pmatrix}0 & I\\ \alpha\Laplace-\beta(x) & 0\end{pmatrix}\]
nicht garantiert werden können. Basierend auf der Halbgruppentheorie, welche schon für die Existenztheorie in Kapitel \ref{chapter:existencetheory} verwendet wurde, werden wir hier ebenfalls Konvergenz zweiter Ordnung bezüglich der Zeitschrittweite $\tau$ beweisen können. Die Vorgehensweise ist angelehnt an den Beweis für Theorem 2.1b aus \autocite{jahnkelubich2000} (Jahnke und Lubich).
\subsubsection*{Folgerungen aus Existenztheorie}
Sei $R=H^1(\Torus^d)\times L^2(\Torus^d)$ mit zugehöriger Norm
\[\norm{v}_R^2=\norm{v_1}_{H_1}^2+\norm{v_2}_{L^2}^2.\]
Wir schreiben die KGG in der Form
\[\partialdt{u}=\underbrace{\begin{pmatrix}0 & I\\ \alpha\Laplace & 0\end{pmatrix}}_{\eqqcolon A}u+\underbrace{\begin{pmatrix}0 & 0\\ -\beta & 0\end{pmatrix}}_{\eqqcolon B}u, \quad u(0)\in D(A).\]
Dabei ist $D(A)\coloneqq H^2(\Torus^d)\times H^1(\Torus^d)$ der Definitionsbereich von $A$ und wir können für $\alpha>0$, $0<\beta\in L^\infty(\Torus^d)$ eine Lösung $u\in D(A)$ garantieren. Zu $v\in D(A)$ definieren wir die Graphennorm
\[\norm{v}_{D(A)}^2=\norm{v}_R^2+\norm{Av}_R^2.\]
Der Operator $A$ erzeugt eine Halbgruppe $e^{tA}$ und erfüllt $\norm{e^{tA}}\le e^t$ (vgl. (\ref{eqn:normgroupofa})). Hierbei ist etwas Vorsicht geboten, da diese Norm zwar äquivalent zur hier verwendeten Norm ist, sich aber um einen Faktor $\alpha$ unterscheidet. Ist $\alpha\le 1$, so gilt ebenfalls $\norm{e^{tA}}_R\le e^t$, ist $\alpha>1$ gilt lediglich $\norm{e^{tA}}_R\le \sqrt{\alpha} e^t$. Um diese Fallunterscheidung zu vermeiden definieren wir $\alpha_1\coloneqq \max(1,\sqrt{\alpha})$ und verwenden
\[\norm{e^{tA}}_R\le \alpha_1 e^t, \quad t\ge 0.\]
Für den Operator $B$ gilt analog zur Abschätzung (\ref{eqn:normgroupofb}) 
\[\norm{e^{tB}}_R\le 1+\norm{\beta}_\infty t, \quad t\ge 0.\]
\subsubsection*{Abschätzung des lokalen Fehlers}
Um für einen Zeitpunkt $t$ die exakte Lösung $e^{t(A+B)}u(0)$ der KGG mit der Approximation $e^{tA/2}e^{tB}e^{tA/2}u(0)$ des Splittings vergleichen zu können, verwenden wir eine Darstellung der \emph{Variation der Konstanten Formel} aus \autocite{carassco2007}.
\begin{maththeorem}[Variation der Konstanten nach Alekseev]
\label{th:varofconstantsalkeseev}
Sei eine Differentialgleichung 
\begin{equation}
\label{eqn:varofconsts}
y'(t)=f(t,y)+g(t,y),\quad y(0)=y_0
\end{equation}
gegeben. Sei $z(t,t_0,y_0)$ die Lösung der Differentialgleichung 
\[z'(t)=f(t,z), \quad z(t_0)=y_0\]
und
\[\phi(t,s,\xi)\coloneqq\frac{\partial z}{\partial y_0}(t,s,\xi).\]
Dann löst
\[y(t,y_0)=z(t,0,y_0)+\int_0^t\phi(t,s,y(s))g(s,y(s))ds\]
die Gleichung (\ref{eqn:varofconsts}).
\end{maththeorem}
In unserem Fall ist $f(t,y)=Ay(t)$, $g(t,y)=By(t)$ und es gilt daher
\begin{align*}
z(t,t_0,y_0)&=e^{(t-t_0)A}y_0\\
\phi(t,s,\xi)&=e^{(t-s)A}
\end{align*}
und somit insgesamt
\begin{equation}
\label{eqn:kgg_voc_raw}
e^{t(A+B)}u(0)=e^{tA}u(0)+\int_0^te^{(t-s)A}Be^{s(A+B)}u(0)ds.
\end{equation}
Zur Berechnung des lokalen Fehlers ausgehend von $u\coloneqq u(t_n)$ nach $u(t_n+\tau)$ schreiben wir unter doppelter Verwendung von (\ref{eqn:kgg_voc_raw}) die exakte Lösung als:
\begin{equation}
\begin{split}
e^{\tau(A+B)}u&=e^{\tau A}u+\int_0^\tau e^{(\tau - s)A}Be^{s(A+B)}uds\\
&=\underbrace{e^{\tau A}u}_{\eqqcolon E_0(\tau,u)}+\underbrace{\int_0^\tau e^{(\tau - s)A}Be^{sA}uds}_{\eqqcolon E_1(\tau,u)}
+\underbrace{\int_0^\tau e^{(\tau - s)A}B\int_0^s e^{(s-r)A}Be^{r(A+B)}udrds}_{\eqqcolon E_2(\tau, u)}
\end{split}
\end{equation}
Entsprechend schreiben wir mithilfe der Reihenentwicklung von $e^{\tau B}$ die Splitting Approximation als:
\begin{equation}
\begin{split}
e^{\tau A/2}e^{\tau B}e^{\tau A/2}u&=\underbrace{e^{\tau A}u}_{\eqqcolon S_0(\tau,u)}+\underbrace{e^{\tau A/2}\tau Be^{\tau A/2}u}_{\eqqcolon S_1(\tau,u)}+\underbrace{\frac{\tau^2}{2}e^{\tau A/2}B^2e^{\tau A/2}u}_{\eqqcolon S_2(\tau,u)}\\
&\quad +\underbrace{e^{\tau A/2}\left(\sum_{k=3}^\infty \frac{(\tau B)^k}{k!}\right)(\tau B)e^{\tau A/2}u}_{\eqqcolon S_3(\tau,u)}
\end{split}
\end{equation}
Wir vergleichen nun die Komponenten $E_i(\tau,u)$ der exakten Lösung mit den jeweiligen Komponenten $S_i(\tau,u)$ der Splitting Approximation und zeigen jeweils einen Fehler der Ordnung $\mathcal{O}\left(\tau^3\right)$.\\
Es gilt $E_0-S_0\equiv 0$.\\
Die dritte Komponente $S_3$ der Splitting Approximation ist bereits von Ordnung drei:
\begin{align*}
\norm{S_3(\tau,u)}_R&\le \alpha_1e^{\tau/2}\frac{\tau^3}{6}\norm{B}^3_R\alpha_1e^{\tau/2}\norm{u}_R+\mathcal{O}\left(\tau^4\right)\\
&= \tau^3\frac{\alpha_1^2}{6}\norm{B}^3_Re^\tau\norm{u}_R+\mathcal{O}\left(\tau^4\right)
\end{align*}
Für den Vergleich der ersten Komponenten $E_1$ und $S_1$ definieren wir
\[f(s)\coloneqq e^{(\tau - s)A}Be^{sA}u,\quad s\in[0,\tau].\]
Es gilt für $f$ folgende Taylor Darstellung:
\[f(s)=f(\tau/2)+(s-\tau/2)f'(\tau/2)+\int_{\tau/2}^s\int_{\tau/2}^rf''(q)dq\,dr\]
Dabei gilt für die Ableitungen von $f$:
\begin{align*}
f'(s)&=e^{(\tau -s)A}\underbrace{(BA-AB)}_{\eqqcolon [B,A]}e^{sA}u\\
f''(s)&=e^{(\tau -s)A}[[B,A],A]e^{sA}u
\end{align*}
Wir können nun die Komponenten vergleichen:
\begin{align}
E_1(\tau,u)-S_1(\tau,u)&=\int_0^\tau f(s)ds-\tau f(\tau/2)\nonumber\\
&=\underbrace{\int_0^\tau f(\tau/2)ds}_{=\tau f(\tau/2)}+\underbrace{\int_0^\tau (s-\tau/2)f'(\tau/2)ds}_{=0}\nonumber\\
&\qquad+\int_0^\tau\int_{\tau/2}^s\int_{\tau/2}^rf''(q)dq\,dr\,ds-\tau f(\tau/2)\nonumber\\
&=\int_0^\tau\int_{\tau/2}^s\int_{\tau/2}^r f''(q)dq\,dr\,ds\nonumber\\
&=\int_0^\tau\int_{\tau/2}^s\int_{\tau/2}^r e^{(\tau -q)A}[[B,A],A]e^{qA}udq\,dr\,ds\label{eqn:order_first_components}
\end{align}
Um den Fehler der ersten Komponenten $E_1$ und $S_1$ abschätzen zu können benötigen wir eine entsprechende Abschätzung für den Kommutator $[[B,A],A]$.
\begin{mathlemma}[Kommutatorabschätzung]
\label{lemma:commutator}
Für alle $v\in D(A)$ gilt
\[\norm{[[B,A],A]v}_R\le c\norm{v}_{D(A)}.\]
\end{mathlemma}
\begin{proof}
Es ist $[[B,A],A]=[BA-AB,A]=BA^2-2ABA+A^2B$ und daher gilt für hinreichend glattes $\beta$ und eine Konstante $c>0$ für $v\in D(A)$:
\begin{align*}
\norm{[[B,A],A]v}_R^2&=\norm{\begin{pmatrix}2\beta v_2\\-(\beta\alpha\Laplace v_1+\alpha\Laplace(\beta v_1))\end{pmatrix}}_R^2\\
&=\underbrace{4\norm{\beta v_2}_{H^1}^2}_{\le c^2\norm{v_2}_{H^1}^2}+\underbrace{\norm{\beta\alpha\Laplace v_1 + \alpha\Laplace(\beta v_1)}_{L^2}^2}_{\le c^2\norm{\alpha \Laplace v_1}_{L^2}^2+c^2\norm{v_1}_{H^1}^2}\\
&\le c^2 \left(\norm{v}_R^2+\norm{Av}_R^2\right)=c^2\norm{v}_{D(A)}^2
\end{align*}
\end{proof}
Für die Graphennorm gilt ebenfalls $\norm{e^{tA}}_{D(A)}\le \alpha_1e^t$:
\begin{align*}
\norm{e^{tA}v}_{D(A)}^2&=\norm{e^{tA}v}_R^2+\norm{Ae^{tA}v}_R^2\\
&=\norm{e^{tA}v}_R^2+\norm{e^{tA}Av}_R^2\\
&=\alpha_1^2e^{2t}\left(\norm{v}_R^2+\norm{Av}_R^2\right)=\alpha_1^2e^{2t}\norm{v}_{D(A)}^2
\end{align*}
Insgesamt folgt nun aus (\ref{eqn:order_first_components}) mit Lemma \ref{lemma:commutator} und der Abschätzung für die Graphennorm:
\begin{align*}
\norm{E_1(\tau,u)-S_1(\tau,u)}_R&=\norm{\int_0^\tau f(s)ds-\tau f(\tau/2)}_R\\
&\le \int_0^\tau\int_{\tau/2}^s\int_{\tau/2}^r e^{\tau - q}c\alpha_1^2e^q\norm{u}_{D(A)}dq\,dr\,ds\\
&=\tau^3c\alpha_1^2e^\tau\norm{u}_{D(A)}
\end{align*}
Zuletzt vergleichen wir die Komponenten $E_2$ und $S_2$. Wiederum definieren wir eine Hilfsfunktion $g$ durch
\[g(s,r)\coloneqq e^{(\tau-s)A}Be^{(s-r)A}Be^{rA}u,\quad 0\le r\le s\le \tau.\]
Dann gilt:
\begin{align*}
&E_2(\tau,u)-S_2(\tau,u)=\int_0^\tau\int_0^se^{(\tau-s)A}Be^{(s-r)A}Be^{r(A+B)}udr\,ds-\frac{\tau^2}{2}e^{\tau A/2}B^2e^{\tau A/2}u\\
&=\int_0^\tau\int_0^s g(s,r) + \underbrace{e^{(\tau-s)A}Be^{(s-r)A}B\left(e^{r(A+B)}-e^{rA}\right)u}_{\eqqcolon Z(r,s,u)}dr\,ds-\frac{\tau^2}{2}e^{\tau A/2}B^2e^{\tau A/2}u
\end{align*}
Der integrierte Summand $Z$ ist dabei bereits von Ordnung drei. Dies erhält man durch kurze Rechnung unter Verwendung von Satz \ref{th:varofconstantsalkeseev}:
\begin{align*}
&\norm{\int_0^\tau\int_0^s Z(r,s,u)dr\,ds}_R\\
&\le \int_0^\tau\int_0^s \alpha_1^2e^{\tau-s}\norm{B}_Re^{s-r}\norm{B}_R\lVert\big(\underbrace{e^{r(A+B)}}_{=e^{rA}u+\int_0^r e^{(r-q)A}Be^{q(A+B)}udq}-e^{rA}\big)u\rVert_Rdr\,ds\\
&\le \tau^2\alpha_1^2e^{\tau-r}\norm{B}_R^2\norm{\int_0^re^{(r-q)A}Be^{q(A+B)}udq}_R\\
&\le \tau^3\alpha_1^3e^{\tau}\norm{B}_R^3\max_{s\in[0,\tau]}\norm{u(t_n+s)}_R
\end{align*} 
Somit gilt für die zweiten Komponenten
\begin{align*}
\norm{E_2(\tau,u)-S_2(\tau,u)}_R&\le \norm{\int_0^\tau\int_0^sg(s,r)dr\,ds-\frac{\tau^2}{2}g(\tau/2,\tau/2)}_R+c\tau^3e^\tau\\
&=\norm{\int_0^\tau\int_0^s\left(g(s,r)-g(\tau/2,\tau/2)\right)dr\,ds}_R+c\tau^3e^\tau.
\end{align*}
Um eine Abschätzung für $g(s,r)-g(\tau/2,\tau/2)$ zu erhalten definieren wir für $0\le r\le s\le\tau$ den Richtungsvektor $\nu\coloneqq (s,r)^T-\frac{\tau}{2}(1,1)^T$ und für $\xi\in[0,1]$ die Strecke $y$ durch $y(\xi)\coloneqq \frac{\tau}{2}(1,1)^T+\xi \nu$.\\
Es gilt:
\begin{align*}
\norm{\nu}^2&=(s-\tau/2)^2+(r-\tau/2)^2=s^2-s\tau+\tau^2/4+r^2-r\tau+\tau^2/4\\
&=\tau^2/2+r(r-\tau)+s(s-\tau)\le \tau^2/2
\end{align*}
Daher können wir wie folgt abschätzen:
\begin{align*}
&\max_{0\le r\le s\le \tau}\norm{g(s,r)-g(\tau/2,\tau/2)}_R=\max_{0\le r\le s\le \tau}\norm{g(y(1))-g(y(0))}_R\\
&=\max_{0\le r\le s\le \tau}\norm{\int_0^1\frac{d}{d\xi}g(y(\xi))d\xi}_R=\max_{0\le r\le s\le \tau}\norm{\int_0^1\nabla g(y(\xi))^T\nu d\xi}_R\\
&\le c\tau \max_{0\le r\le s\le \tau}\norm{\nabla g(s,r)^T\begin{pmatrix}1\\1\end{pmatrix}}_R
\end{align*}
Daraus folgt
\begin{align*}
\norm{E_2(\tau,u)-S_2(\tau,u)}_R
&\le\norm{\int_0^\tau\int_0^s(g(s,r)-g(\tau/2,\tau/2))dr\,ds}_R+c\tau^3e^\tau\\
&\le c\tau^3\max_{0\le r\le s\le \tau}\norm{\partial_sg(s,r)+\partial_rg(s,r)}_R+c\tau^3e^\tau.
\end{align*}
Für die partiellen Ableitungen von $g$ gilt
\begin{align*}
\partial_sg(s,r)&=e^{(\tau-s)A}[B,A]e^{(s-r)A}Be^{rA}u\\
\partial_rg(s,r)&=e^{(\tau-s)A}Be^{(s-r)A}[B,A]e^{rA}u.
\end{align*}
Da der Kommutator $[B,A]$ beschränkt ist mit
\[\norm{[B,A]}_R=\norm{\begin{pmatrix}\beta & 0\\0 & -\beta\end{pmatrix}}_R\le \norm{\beta}_\infty\]
folgt für die partiellen Ableitungen direkt
\begin{align*}
\norm{\partial_sg(s,r)}_R&\le \alpha_1^3 e^{\tau-s}\norm{\beta}_\infty e^{s-r}\norm{B}_R e^r\norm{u}_R=\alpha_1^3e^\tau\norm{\beta}_\infty\norm{B}_R\norm{u}_R\\
\norm{\partial_rg(s,r)}_R&\le ce^\tau \norm{u}_R.
\end{align*}
Zusammengefasst haben wir nun für den lokalen Fehler folgende Abschätzung bewiesen:
\begin{align*}
&\norm{e^{\tau(A+B)}u-e^{\tau A/2}e^{\tau B}e^{\tau A/2}u}_R\\
&\le\norm{E_0(\tau,u)-S_0(\tau,u)}_R
+\norm{E_1(\tau,u)-S_1(\tau,u)}_R
+\norm{E_2(\tau,u)-S_2(\tau,u)}_R
+\norm{S_3(\tau,u)}_R\\
&\le c\tau^3e^\tau\norm{u}_{D(A)}+c\tau^3e^\tau\norm{u}_R+c\tau^3e^\tau\norm{u}_R+\mathcal{O}\left(\tau^4\right)\\
&\le \tilde{c}\tau^3e^\tau \norm{u}_{D(A)}+\mathcal{O}\left(\tau^4\right),\quad \tilde{c}>0
\end{align*}
\subsubsection*{Abschätzung des globalen Fehlers}
\begin{maththeorem}[Strang-Splitting für die KGG]
Das Strang-Splitting 
\[u^n\coloneqq \left(e^{\tau A/2}e^{\tau B}e^{\tau A/2}\right)^nu(0)\]
für die Klein-Gordon-Gleichung (\ref{kgg}) mit Lösung $u$, $\alpha>0$, $0<\beta\in L^\infty(\Torus^d)\cap C^2(\Torus^d)$ und
\[A=\begin{pmatrix}0 & I\\ \alpha\Laplace\end{pmatrix}, \quad B=\begin{pmatrix}0 & 0\\ -\beta(x) & 0\end{pmatrix}\]
ist konvergent von Ordnung 2 bezüglich der Zeitschrittweite $\tau=\frac{t_n}{n}>0$:
\[u^n-u(t_n)\le \hat{c}\tau^2, \qquad \hat{c}(\alpha,\beta,t_n,\max_{j=0,\dots,n-1}\norm{u(t_j)}_{D(A)})>0\]
\end{maththeorem}
\begin{proof}
Sei der Lösungsoperator $T$ der exakten Lösung der KGG definiert als
\[T(t)\coloneqq e^{t(A+B)},\quad t\ge 0\]
und der Splittingoperator $S$ des Strang-Splittings für die KGG als
\[S(t)\coloneqq e^{tA/2}e^{tB}e^{tA/2},\quad t\ge 0.\]
Dann können wir den globalen Fehler mithilfe einer Teleskopsumme schreiben als
\begin{align*}
u^n-u(t_n)&=S^n(\tau)u(0)-T^n(\tau)u(0)\\
&=\sum_{j=0}^{n-1}S^{n-j-1}(\tau)\left(S(\tau)-T(\tau)\right)T^j(\tau)u(0).
\end{align*}
Daraus folgt unter der Verwendung der Abschätzung des lokalen Fehlers und wegen $\norm{v}^2=\norm{v_1}_{H_\alpha^1}^2+\norm{v_2}_{L^2}^2\le \alpha_1 \norm{v}_R^2$ schlussendlich die Konvergenz zweiter Ordnung für das Strang-Splitting:
\begin{align*}
\norm{u^n-u(t_n)}&\le \sum_{j=0}^{n-1}\norm{S^{n-j-1}(\tau)}\alpha_1\norm{(S(\tau)-T(\tau))u(t_j)}_R\\
&\le \tilde{c}\alpha_1\tau^3ne^\tau\max_{j=0,\dots,n-1}\big((1+\norm{\beta}_\infty\underbrace{\tau}_{=\frac{t_n}{n}})e^\tau\big)^{n-j-1}\norm{u(t_j)}_{D(A)}\\
&\le \tilde{c}\alpha_1\tau^2t_ne^{\norm{\beta}_\infty t_n}e^{t_n}\max_{j=0,\dots,n-1}\norm{u(t_j)}_{D(A)}
=\mathcal{O}\left(\tau^2\right)
\end{align*}
\end{proof}
\subsection{Numerischer Löser für die Klein-Gordon-Gleichung}
\label{chapter:solver_kgg}
Dieser Abschnitt bildet das Fundament, auf dem viele numerische Lösungsverfahren basieren werden. Inhalt und Notation basieren zu Teilen auf \autocite{patrickdiplom}. Um ein Operatorsplitting auf die KGG anwenden zu können muss diese zuerst in eine Gleichung mit Zeitableitung erster Ordnung in der Form von (\ref{orddgl}) umgeschrieben werden. Eine mögliche Darstellung ist
\begin{align}
\partialdtt{u}(t,x)&=\alpha \Laplace u(t,x) - \beta(x)u(t,x)\nonumber\\
\iff
\partialdt{\begin{pmatrix}
u\\
v
\end{pmatrix}}(t,x)&=
\begin{pmatrix}
0 & I\\
\alpha \Laplace - \beta(x) & 0
\end{pmatrix}
\begin{pmatrix}u\\v\end{pmatrix}(t,x)\nonumber\\
\label{eqn:formalsplit_kgg}
&=\left[\begin{pmatrix} 0 & wI\\ \alpha \Laplace & 0\end{pmatrix} 
+ \begin{pmatrix} 0 & (1-w)I\\ -\beta(x) & 0\end{pmatrix}\right]
\begin{pmatrix}u\\v\end{pmatrix}(t,x)
\end{align}
für ein Gewicht $w\in [0,1]$. Doch bevor wir dies als Grundlage für ein Splitting verwenden, müssen wir den Operator $\Laplace$ genauer untersuchen.
\subsubsection*{Ortsdiskretisierung durch Fourier-Pseudospektralmethode}
Um einen numerischen Zugang zum Laplace-Operator $\Laplace$ zu bekommen benötigen wir zuerst eine Diskretisierung des Ortes $x_j=-\pi+2\pi\frac{j}{N}\in [-\pi,\pi)$ für $j=0,\dots,N-1$ und $N\in\N$. Da wir periodische Lösungen $u$ der KGG suchen, bietet es sich an $u$ mithilfe von trigonometrischen Polynomen, d.h. einer Linearkombination der trigonometrischen Funktionen $\sin(k\cdot)$ und $\cos(k\cdot)$ für $k\in\Z$, zu approximieren. In komplexer Darstellung erfüllen diese für $k,\ell\in\Z$ die Orthogonalitätseigenschaft 
\[\int_{-\pi}^\pi e^{ikx}\cdot e^{i\ell x}dx=\begin{cases}0,\quad k\ne \ell\\ 2\pi,\quad k=\ell.\end{cases}\]
Diese Approximation mit endlich vielen Basispolynomen $e^{ik\cdot}$ nennt man endliche Fourier-Approximation der Funktion $u$. Wir werden den Ansatz zuerst ausführlich für $d=1$ erläutern und später die Verallgemeinerung auf höhere Dimensionen aufzeigen.\\
Die Fourier-Approximation ist für jedes $t>0$, $N\in 2\N$ und eine Indexmenge $\mathcal{J}_N=\left\lbrace -\frac{N}{2},\dots,-1,0,1,\dots,\frac{N}{2}-1\right\rbrace$ definiert durch
\begin{equation}
\label{eqn:fourier_approx}
u(t,x)\approx \sum_{k\in\mathcal{J}_N}\fourier{u}_k(t)e^{ikx}, \quad x\in\Torus
\end{equation}
wobei für die Fourier-Koeffizienten $\fourier{u}_k(t)=\frac{1}{2\pi}\int_{-\pi}^\pi u(t,x)e^{-ikx}dx\in\Complex$ gilt. \\
Um die Konvergenz der Fourier-Approximation einer Funktion zu erhalten benötigen wir gewisse Anforderungen an die Glattheit der Funktion. Dabei sind bereits Stetigkeit und stückweise stetige Differenzierbarkeit ausreichend für eine gleichförmige Konvergenz. 
\begin{mathbsp}
Die Konvergenz der Fourierapproximation und die Möglichkeit, Ableitungen im Fourierraum durchzuführen, demonstrieren wir an dieser Stelle durch zwei Beispiele.\\
Wir betrachten zu einer periodischen Funktion $f\colon\Torus\to\R$ die diskrete Fourierapproximation
\[f(x)\approx \sum_{k\in \mathcal{J}_N}\fourier{f}_ke^{ikx}\]
und die approximierte Ableitung $p$-ter Ordnung
\[\dxp{f}{p}(x)\approx \sum_{k\in \mathcal{J}_N}(ik)^p\fourier{f}_ke^{ikx}\]
für die Beispiele $f_1(x)=-\sin(x)e^{-\sin(x)}$ und $f_2(x)=|x|$. Beachte, dass die klassische Ableitung erster Ordnung von $f_2$ nicht existiert, da $f_2$ in $0$ nicht differenzierbar ist. Wir interpretieren die Approximation daher als Approximation an die schwache Ableitung und messen die Konvergenz bezüglich der diskreten $L2$-Norm.
\begin{figure}[!htb]
  \includegraphics[width=0.9\linewidth]{Figures/spectral_derivative_error_cont.png}
  \caption{Konvergenz der spektralen Ableitung zweiter Ordnung von $f_1$.}
\end{figure}
\begin{figure}[!htb]
  \includegraphics[width=0.9\linewidth]{Figures/spectral_derivative_error_discont.png}
  \caption{Konvergenz der spektralen Ableitung zweiter Ordnung von $f_2$.}
\end{figure}
Wir erkennen, dass die analytische Funktion $f_1$ eine exponentielle Konvergenz aufweist und bereits für $N=64$ Punkte im Bereich der Maschinengenauigkeit liegt. Rechenfehler sorgen bei $N>64$ für eine Aufsummierung von kleinen Überschwingungen und einen langsam wachsenden Fehler.\\
Die stetige Funktion $f_2$ mit stückweise stetiger nicht-periodischer Ableitung leidet bei der Approximation unter dem Gibbs-Phänomen und deutlich langsamerer Konvergenz.
\end{mathbsp}

Formalisieren wir nun die diskrete Fourier-Transformation, die wir verwenden möchten, um eine Approximation an die Fourier-Koeffizienten zu erhalten.
\begin{mathdef}[Diskrete Fourier-Transformation]
Die lineare Abbildung $\mathcal{F}_N\colon\Complex^N\to\Complex^N$ definiert durch
\[\mathcal{F}_Nz=\fourier{z},\qquad\text{mit}\quad \fourier{z}_k=\sum_{j=0}^{N-1}e^{-2\pi i\frac{jk}{N}}z_j\]
heißt diskrete Fourier-Transformation.
\end{mathdef}
Anstelle die direkte Implementierung von $\mathcal{F}_N$ zu verwenden, welche $\mathcal{O}(N^2)$ Rechenschritte benötigt, werden wir auf die deutlich schnellere Berechnung der Abbildung in $\mathcal{O}(N\log N)$ Schritten zurückgreifen. Diese ist unter dem Namen \emph{Fast-Fourier-Transformation} (FFT) bekannt. Da diese auf der Annahme $N=2^p$ für ein $p\in\N$ basiert, werden wir in Zukunft nur noch solche Approximationen verwenden. Dies ist wichtig, um eine optimal schnelle Berechnung der Lösung der KGG zu gewährleisten. Ist $N$ keine Potenz von 2, so runden FFT-Bibliotheken $N$ üblicherweise auf die nächsthöhere Potenz von 2 und man muss eine potentiell erhöhte Rechenzeit in Kauf nehmen.\\
Ohne Beweis gilt $\mathcal{F}_N\overline{\mathcal{F}}_N=NI$ und somit hat die inverse Fourier-Transformation beinahe die selbe Gestalt wie die Fourier-Transformation selbst und kann ebenso schnell berechnet werden.\\
Im Folgenden nehmen wir an, die Fourier-Approximation (\ref{eqn:fourier_approx}) von $u$ sei exakt und berechnen für den $j$-ten Punkt $x_j$ der Diskretisierung:
\begin{equation}
\label{eqn:laplace_approxu}
\Laplace u(t,x_j)=\sum_{k\in\mathcal{J}_N}\fourier{u}_k(t)\partial^2_x e^{ikx_j}=\sum_{k\in\mathcal{J}_N}-k^2\fourier{u}_k(t)e^{ikx_j}
\end{equation}
Dabei ist wegen $d=1$ der Laplace-Operator $\Laplace$ darstellbar als $\Laplace=\partial^2_x$.\\
Betrachten wir nun $(\partial^2_x u(t,x_j))_{j=0,\dots,N-1}$ für den Vektor $u_N(t)=(u(t,x_j))_{j=0,\dots,N-1}$ so gilt
\[(\partial^2_x u(t,x_j))_{j=0,\dots,N-1}\approx \mathcal{F}_N^{-1}\left(\big(-k^2\big)_{k\in\mathcal{J}_N}\odot\mathcal{F}_Nu_N(t)\right),\]
wobei $\odot$ die komponentenweise Multiplikation der Vektoren bezeichnet.\\
Damit erhalten wir für $\beta_N=(\beta(x_j))_{j=0,\dots,N-1}$ die im Ort diskretisierte KGG
\begin{equation}
\label{eqn:kgg_discretespace}
\dtt{u}_N(t)=\alpha \mathcal{F}_N^{-1}\left(\big(-k^2\big)_{k\in\mathcal{J}_N}\odot\mathcal{F}_Nu(t)_N\right) -\beta_N\odot u_N(t).
\end{equation}
Diese werden wir nun in ein System erster Ordnung umschreiben, um anschließend ein Splitting darauf anzuwenden.\\
Es gilt für $t>0$, $v_N(t)\coloneqq \dt u_N(t)$ und ein Gewicht $w\in [0,1]$ die zu (\ref{eqn:kgg_discretespace}) äquivalente Darstellung
\begin{align}
\label{eqn:kgg_discrete_first_order_part1}
\dt{\begin{pmatrix}u_N\\v_N\end{pmatrix}}(t)&=
\begin{pmatrix}0 & wI_N\\ \alpha\mathcal{F}_N^{-1}\left(\big(-k^2\big)_{k\in\mathcal{J}_N}\odot\mathcal{F}_N (\cdot )\right) & 0\end{pmatrix}
\begin{pmatrix}u_N\\v_N\end{pmatrix}(t)\\
\label{eqn:kgg_discrete_first_order_part2}
&\quad+\begin{pmatrix}0 & (1-w)I_N\\ -\diag({\beta_N}) & 0\end{pmatrix}
\begin{pmatrix}u_N\\v_N\end{pmatrix}(t).
\end{align}
\subsubsection*{Numerischer Fluss des ersten Teils}
Zuerst betrachten wir den ersten Teil der im Ort diskretisierten KGG (\ref{eqn:kgg_discrete_first_order_part1}) und schreiben diesen für $\fourier{u}_N=\mathcal{F}_Nu_N$ und $\fourier{v}_N=\mathcal{F}_Nv_N$ als
\begin{align*}
\dt{\begin{pmatrix}u_N\\v_N\end{pmatrix}}(t)&=
\begin{pmatrix}0 & wI_N\\ \alpha\mathcal{F}_N^{-1}\left(\big(-k^2\big)_{k\in\mathcal{J}_N}\odot\mathcal{F}_N (\cdot )\right) & 0\end{pmatrix}
\begin{pmatrix}u_N\\v_N\end{pmatrix}(t)\\
\equivalent 
\dt{\begin{pmatrix}\fourier{u}_N\\\fourier{v}_N\end{pmatrix}}(t)&=
\begin{pmatrix}0 & wI_N\\ \alpha\diag\big(-k^2\big)_{k\in\mathcal{J}_N} & 0\end{pmatrix}
\begin{pmatrix}\fourier{u}_N\\\fourier{v}_N\end{pmatrix}(t).
\end{align*}
Damit haben wir nun ein System gewöhnlicher Differentialgleichungen der Größe $2N$ im Fourierraum, welches wir explizit über die Matrixexponentialfunktion lösen können:
\[\begin{pmatrix}\fourier{u}_N\\\fourier{v}_N\end{pmatrix}(t)=\exp\underbrace{\left(t\begin{pmatrix}0 & wI_N\\ \alpha\diag\big(-k^2\big)_{k\in\mathcal{J}_N} & 0\end{pmatrix}\right)}_{=M}
\begin{pmatrix}\fourier{u}_N\\\fourier{v}_N\end{pmatrix}(0)\]
Die Blockmatrix $M$ lässt sich in eine äquivalente Blockdiagonalmatrix umformen, indem zueinander gehörende Einträge der $\fourier{u}_N$ und $\fourier{v}_N$ nebeneinander getauscht werden. Konkret bedeutet dies, dass die $i$-te Komponente des Vektors $\fourier{u}_N$ neben die $i$-te Komponente des Vektors $\fourier{v}_N$ getauscht wird. Die Matrixexponentialfunktion von $M$ lässt sich dann durch die Matrixexponentialfunktion der $2\times 2$ Blöcke $M_k$ berechnen:
\[\exp(M_k)=\exp\begin{pmatrix}0 & wt\\ -\alpha k^2t & 0\end{pmatrix}=
\begin{pmatrix}\cos(t\sqrt{\alpha w}|k|) & \sinc(t\sqrt{\alpha w}|k|)tw\\-\sinc(t\sqrt{\alpha w}|k|)\alpha |k|^2t & \cos(t\sqrt{\alpha w}|k|)\end{pmatrix}\]
Wir fassen nun die Ergebnisse zum numerischen Fluss des ersten Teil des Splittings (\ref{eqn:kgg_discrete_first_order_part1}) zusammen.\\
Seien $g$ und $h$ die Anfangswerte, so gilt $\fourier{u}_N(0)=\mathcal{F}_Ng$ und $\fourier{v}_N(0)=\mathcal{F}_Nh$. Die Lösung an den Stellen $x_j=-\pi+2\pi\frac{j}{N}\in [-\pi,\pi)$ für $j=0,\dots,N-1$ lässt sich darstellen als
\begin{align*}
u(t,x_j)&=\left(\mathcal{F}_N^{-1}\left[\mathcal{F}_Ng\odot \big(\cos(t\sqrt{\alpha w}|k|)\big)_{k\in\mathcal{J}_N} + \mathcal{F}_Nh\odot \big(\sinc(t\sqrt{\alpha w}|k|)tw\big)_{k\in\mathcal{J}_N}\right]\right)_j\\
\partialdt{u}(t,x_j)&=\left(\mathcal{F}_N^{-1}\left[\mathcal{F}_Ng \odot \big(-\sinc(t\sqrt{\alpha w}|k|)\alpha|k|^2t\big)_{k\in\mathcal{J}_N}+\mathcal{F}_Nh\odot \big(\cos(t\sqrt{\alpha w}|k|)\big)_{k\in\mathcal{J}_N}\right]\right)_j
\end{align*}
Man beachte, dass die Sortierung der Fourier-Koeffizienten in verschiedenen Programmiersprachen verschiedenen Notationen folgt und entsprechend die Indizierung angepasst werden muss. Beispielsweise gilt für die Python3 Bibliothek \emph{numpy} durch die entsprechende Funktion \emph{numpy.fft.fftfreq(8)*8} die Konvention
\[\mathcal{J}_8=\left( 0,  1,  2,  3, -4, -3, -2, -1\right)\]
wobei Matlab die ähnliche Konvention
\[\mathcal{J}_8=\left( 0,  1,  2,  3, 4, -3, -2, -1\right)\]
verwendet.\\[0.3cm]
Obige Erläuterungen gelten für eine räumliche Dimension ($d=1$). Will man nun den Ansatz auf mehrere Dimensionen erweitern, so erhält man ein sehr ähnliches Ergebnis.
Führt man die Fourier-Transformation in jeder Dimension durch, so ergibt sich für $d=2$ die Approximation
\[u(t,x)\approx\sum_{k_1\in\mathcal{J}_N}\fourier{u}_{k_1}(t,x_2)e^{ik_1x_1}=\sum_{k_1\in\mathcal{J}_N}\sum_{k_2\in\mathcal{J}_N}\fourier{u}_{k_1,k_2}(t)e^{i(k_1x_1+k_xx_2)}.\]
Die Funktion $\fourier{u}_{k_1}$ bezeichnet die Fourier-Koeffizienten für die eindimensionale Fourier-Approximation entlang der Richtung $x_1$. Durch eine wiederholte Fourier"=Approximation dieser Funktion erhalten wir die zweidimensionale Fourier-Approximation mit den Fourier-Koeffizienten $\fourier{u}_{k_1,k_2}$.\\
Analog zu der Approximation (\ref{eqn:laplace_approxu}) erhält man
\[\Laplace u(t,x)=\sum_{k_1\in\mathcal{J}_N}-k_1^2\fourier{u}_{k_1}(t,x_2) e^{ik_1x_1}=\sum_{k_1,k_2\in\mathcal{J}_N}-(k_1^2+k_2^2)\fourier{u}_{k_1,k_2}(t)e^{i(k_1x_1+k_2x_2)}.\]
Das Vorgehen im Mehrdimensionalen unterscheidet sich also nur durch eine aufwändigere Indizierung, ist jedoch im Kern dieselbe. Ersetzt man in obigen Ausführungen für $d=1$ sämtliche $|k|$ durch \[\norm{k}_2=\sqrt{k_1^2+\dots+k_d^2},\]so erhält man, bei passender Indizierung der diskreten Fourier-Approximation, eine Darstellung der Lösung für beliebige Dimensionen $d\in\N$.
\subsubsection*{Method of lines für den zweiten Teil des Splittings}
Einen numerischen Löser für den zweiten Teil (\ref{eqn:kgg_discrete_first_order_part1}) der im Ort diskretisierten KGG erhält man auf ähnliche Weise. Wir suchen für $t>0$, $\beta(x)>0$ und ein Gewicht $\tilde{w}=1-w\in [0,1]$ die Lösung der Differentialgleichung
\begin{equation*}
\dt{\begin{pmatrix}u_N\\v_N\end{pmatrix}}(t)=
\begin{pmatrix}0 & \tilde{w}I_N\\ -\diag({\beta_N}) & 0\end{pmatrix}
\begin{pmatrix}u_N\\v_N\end{pmatrix}(t).
\end{equation*}
Die Struktur der Differentialgleichung zeigt, dass sich ihre Lösung ebenfalls mithilfe der Matrixexponentialfunktion darstellen lässt. Die Matrixexponentialfunktion der Blockmatrix ist wiederum durch nebeneinander Sortieren der $i$-ten Komponenten der Vektoren $u_N$ und $v_N$ äquivalent zu einer Blockdiagonalmatrix mit $2\times 2$ Blöcken auf der Diagonalen. Für diese gelten:
\[\exp\begin{pmatrix}0 & \tilde{w}t\\ -t\beta(x_j) & 0\end{pmatrix}=
\begin{pmatrix}\cos(t\sqrt{\beta(x_j)\tilde{w}}) & \sinc(t\sqrt{\beta(x_j)\tilde{w}})\tilde{w}t\\
-\sinc(t\sqrt{\beta(x_j)\tilde{w}})\beta(x_j)t & \cos(t\sqrt{\beta(x_j)\tilde{w}})\end{pmatrix}\]
Daraus erhalten wir zu den Anfangswerten $g$ und $h$ für festes $x\in \Torus^d$ die explizite Lösung des zweiten Teil des Splittings durch
\[\begin{pmatrix}u\\v\end{pmatrix}(t,x)=
\begin{pmatrix}\cos(t\sqrt{\beta(x)\tilde{w}}) & \sinc(t\sqrt{\beta(x)\tilde{w}})\tilde{w}t\\
-\sinc(t\sqrt{\beta(x)\tilde{w}})\beta(x)t & \cos(t\sqrt{\beta(x)\tilde{w}})\end{pmatrix}
\begin{pmatrix}g\\h\end{pmatrix}(x).\]
Wir benötigen im Gegensatz zum ersten Teil keine feste Ortsdiskretisierung und bekommen sogar eine exakte Lösung des Teilproblems. Da die Punkte für die verschiedenen Teile des Splittings identisch sein müssen, sind wir jedoch durch die Anforderung festgelegt, die die Fourier-Approximation an die Punkte stellt.\\
Mithilfe der \emph{method of lines}, d.h. punktweiser Auswertung der Lösung für alle benötigten $x$, bekommt man schlussendlich eine numerische Lösung.
\subsubsection*{Konkretisierung des Algorithmus}
Wir haben nun zwei separate Einschrittverfahren, die zusammen mit dem Strang-Splitting Framework einen guten Löser für die KGG ergeben. Dieses Lösungsverfahren ist für $d=1$ schematisch als Algorithmus \ref{alg:kgg_solver} dargestellt.
\begin{algorithm}[ht]
    \caption{Strang-Splitting für KGG}
    \label{alg:kgg_solver}
    \begin{algorithmic}[1] % The number tells where the line numbering should start
    	\Function{Fast\_Strang}{$N,u_0,v_0,\alpha,\beta,w,\tau,T$}
    		\State $x_N\gets (-\pi+\frac{2\pi j}{N})_{j=0,\dots,N-1}^T$
            \State $g,h\gets u_0(x_N), v_0(x_N)$
            \State $g,h\gets \text{First\_Part\_Solver}(N, g, h, \alpha, w, \frac{\tau}{2})$
            \State $g,h\gets \text{Second\_Part\_Solver}(x_N, g, h, \beta, 1-w, \tau)$
            \For{$i=1,\dots,\frac{T}{\tau}-1$} \Comment{Annahme: $\frac{T}{\tau}\in\N$} 
            	\State $g,h\gets \text{First\_Part\_Solver}(N, g, h, \alpha, w, \tau)$
            	\State $g,h\gets \text{Second\_Part\_Solver}(x_N, g, h, \beta, 1-w, \tau)$
            \EndFor
            \State $u_1,v_1\gets \text{First\_Part\_Solver}(N, g, h, \alpha, w, \frac{\tau}{2})$            
            \State \textbf{return} $u_1$ \Comment{Approximation an $u(T,x_N)$}
    	\EndFunction
        \Function{Strang\_Step\_KGG}{$N,u_0,v_0,\alpha,\beta,w,\tau$} 
            \State $x_N\gets (-\pi+\frac{2\pi j}{N})_{j=0,\dots,N-1}^T$
            \State $g,h\gets u_0(x_N), v_0(x_N)$
            \State $g,h\gets \text{First\_Part\_Solver}(N, g, h, \alpha, w, \frac{\tau}{2})$
            \State $g,h\gets \text{Second\_Part\_Solver}(x_N, g, h, \beta, 1-w, \tau)$
            \State $u_1,v_1\gets \text{First\_Part\_Solver}(N, g, h, \alpha, w, \frac{\tau}{2})$
            \State \textbf{return} $u_1, v_1$\Comment{Approximation an $u(\tau,x_N)$ und $\dt{u}(\tau,x_N)$}
        \EndFunction
        
        \Function{First\_Part\_Solver}{$N,g,h,\alpha,w,\tau$} 
        	\State Indexmenge $\mathcal{J}_N$ für Fourierkoeffizienten initialisieren
        	\State $\fourier{g}\gets \mathcal{F}_Ng$
        	\State $\fourier{h}\gets \mathcal{F}_Nh$
        	\State $c\gets \big(\cos(\tau\sqrt{\alpha w}|k|)\big)_{k\in\mathcal{J}_N}$
        	\State $s_1\gets \big(\sinc(\tau\sqrt{\alpha w}|k|)\tau w\big)_{k\in\mathcal{J}_N}$
        	\State $s_2\gets \big(-\sinc(\tau\sqrt{\alpha w}|k|)\alpha|k|^2\tau\big)_{k\in\mathcal{J}_N}$
            \State \textbf{return} $\mathcal{F}_N^{-1}\left(\fourier{g}\odot c+\fourier{h}\odot s_1\right),\quad \mathcal{F}_N^{-1}\left(\fourier{g}\odot s_2+\fourier{h}\odot c\right)$
        \EndFunction
        \Function{Second\_Part\_Solver}{$x_N,g,h,\beta,\tilde{w},\tau$} 
        	\State $\beta_N\gets\beta(x_N)$
        	\State $c\gets \cos(\tau\sqrt{\beta_N}\sqrt{\tilde{w}})$
        	\State $s_1\gets \sinc(\tau\sqrt{\beta_N}\sqrt{\tilde{w}})\tilde{w}\tau$
        	\State $s_2\gets -\sinc(\tau\sqrt{\beta_N}\sqrt{\tilde{w}})\beta_N\tau$
        	\State \textbf{return} $g\odot c+h\odot s_1,\quad g\odot s_2+h\odot c$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Dabei ist die Wahl gewisser Parameter jedoch noch unklar:
\begin{itemize}
\item Die Anzahl der Fourierpunkte $N$.
\item Das Gewicht $w\in[0,1]$ für die Gewichtung des Splittings. 
\end{itemize}
Um die Zusammenhänge und Probleme besser zu verstehen, werden wir anhand eines Beispiels mit bekannter exakter Lösung verschiedene Kombinationen der Parameter demonstrieren.
\begin{mathbsp}
\label{bsp:trialfrog2}
Sei $c>2$, dann ist
\begin{align*}
u(t,x)&=\frac{\cos(t)}{\sin(x)+c}\\
u_0(x)&=\frac{1}{\sin(x)+c}\\
v_0(x)&\equiv 0\\
\end{align*}
eine Lösung der eindimensionalen KGG (\ref{kgg}) mit $\alpha=c-2$ und $\beta(x)=1+(c-2)\left(\frac{\sin(x)}{\sin(x)+c}+\frac{2\cos^2(x)}{(\sin(x)+c)^2}\right)$. Wir lösen nun die KGG mithilfe verschiedener Splitting-Varianten und beobachten in Abbildung \ref{fig:splitting_convergence}
\begin{itemize}
\item für das Strang-Splitting die erwartete Konvergenz von Ordnung 2.
\item für das Lie-Trotter-Splitting die erwartete Konvergenz von Ordnung 1.
\item für die schnelle Variante des Strang-Splittings (FastStrang), bei der die äußeren Halbschritte kombiniert werden, exakt den gleichen Fehler wie beim Standard Strang-Splitting.
\item für die umgekehrte Variante des Strang-Splittings (ReversedStrang), wo die Reihenfolge der beiden Aufteilungen der Gleichung vertauscht wurde, eine minimale Abweichung von der Standardvariante.
\item ein deutliches Problem: Wird die Zeitschrittweite $\tau$ zu groß, d.h. ist $1.227\tau>\frac{2\pi}{N}=h$, so ist das Verfahren instabil!
\end{itemize}
\begin{figure}[!htb]
\includegraphics[width=\textwidth]{Figures/splitting_convergence_fix_weight_frog2_cfl.png}
\caption{Konvergenzordnung für verschiedene Splitting-Varianten anhand von Beispiel \ref{bsp:trialfrog2} mit $c=3$, $d=1$, $N=512$, $w=0.5$ zum Zeitpunkt $T=1$.}
\label{fig:splitting_convergence}
\end{figure}
Für die beobachtete Instabilität spielt der Gewichtsfaktor $w$ eine große Rolle. Wäre $w=0$, so entspricht der Löser des ersten Teil des Splittings der Vorschrift
\begin{align*}
u(t,x_N)&=\mathcal{F}_N^{-1}\left(\mathcal{F}_Ng(x_N)\right)=g(x_N)=u(0,x_N)\\
\dt{u}(t,x_N)&=\mathcal{F}_N^{-1}\left(\mathcal{F}_Ng(x_N)\odot \big(-\alpha |k|^2t\big)_{k\in\mathcal{J}_N}\right)+h(x_N)\\
&=t \alpha \mathcal{F}_N^{-1}\left(\mathcal{F}_N\odot \big(-|k|^2\big)_{k\in\mathcal{J}_N}\right)+h(x_N)\\
&=t\alpha \Laplace_N g(x_N)+h(x_N)\\
&\approx t\dtt{u}(0,x_N)+\dt{u}(0,x_N).
\end{align*}
Somit wird in diesem Randfall nur die erste Ableitung geändert und dieses Update entspricht einem expliziten Eulerschritt für die erste Ableitung. Das Splittingverfahren ist dann äquivalent zu einem sogenannten Leapfrog-Verfahren, welches schneller zu berechnen ist, da eine Anwendung von $\mathcal{F}_N^{-1}$ entfällt. Wir erhalten für die Stabilität eine \emph{Courant-Friedrichs-Lewy-Bedingung} (CFL-Bedingung) der Form $\tilde{c}\tau\le h=\frac{2\pi}{N}$. Im Fall $k=0$ entspricht die CFL-Zahl $\tilde{c}$ der CFL-Zahl des expliziten Eulers.\\[0.3cm]
Wir beobachten an Abbildung \ref{fig:splitting_cfl}, dass die CFL-Zahl abhängig von $w$ ist und für $w=1$ ein Minimum annimmt. Die Kurven für verschiedene $N$ weichen dabei voneinander ab, da die Schätzung des kleinsten Zeitpunkts, für welchen die Berechnung instabil ist, heuristisch ist. Wir definieren die Berechnung als instabil, wenn die absolute Steigung im Ordnungsplot kleiner als 1 oder größer als 3 ist oder der beobachtete relative Fehler größer als 1 ist. Diese Instabilitätseffekte beobachtet man für $w\to 1$ erst für große $\tau$, die bei $T=1$ nur sehr wenigen Splittingschritten entsprechen.
\begin{figure}[!htb]
\includegraphics[width=\textwidth]{Figures/cfl_estimations_frog2.png}
\caption{Abhängigkeit der CFL-Zahl anhand von Beispiel \ref{bsp:trialfrog2} mit $c=3$ und $d=1$ zum Zeitpunkt $T=1$.}
\label{fig:splitting_cfl}
\end{figure}
\\[0.3cm]
Wie man an Abbildung \ref{fig:splitting_convergence_w1} erkennt, verhält sich für $w=1$ die Gleichung am stabilsten und kann auch für große Zeitschrittweiten sinnvoll gelöst werden. Dies wird eine große Motivation dafür sein, das Gewicht $w=1$ zu wählen.

\begin{figure}[!htb]
\includegraphics[width=\textwidth]{Figures/splitting_convergence_fix_weight_frog2_cfl_corrected.png}
\caption{Konvergenzordnung für verschiedene Splitting-Varianten anhand von Beispiel \ref{bsp:trialfrog2} mit $c=3$, $d=1$, $N=512$, $w=1$ zum Zeitpunkt $T=1$.}
\label{fig:splitting_convergence_w1}
\end{figure}
Zuletzt sei aber erwähnt, dass die Wahl $w=1$ aus Sicht des minimalen Fehlers selten optimal ist. An Abbildung \ref{fig:splitting_dependence_on_weight} erkennen wir für verschiedene bekannte Lösungen der KGG, dass das Minimum des Fehlers in Abhängigkeit vom Gewicht $w$ sowohl an beiden Rändern, als auch als lokales Minimum auftreten kann. Das genaue Minimum zu bestimmen und dies mit der CFL-Zahl zu kombinieren, um das optimale $w$ zu wählen, kann ein möglicher Ansatz zur Verbesserung des Algorithmus sein. Wir werden dies jedoch nicht weiter verfolgen und uns in den meisten Fällen auf $w=1$ beschränken, da eine Verbesserung des Fehlers dann mit einer Verringerung der Schrittweite $\tau$ besser kontrollierbar ist.
\begin{figure}[!htb]
\includegraphics[width=\textwidth]{Figures/splitting_error_over_weights.png}
\caption{Verschiedene Beispiele von bekannten Lösungen der KGG gelöst mit FastStrang. Der Fehler wird dabei in Abhängigkeit des Gewichts $w$ verglichen.}
\label{fig:splitting_dependence_on_weight}
\end{figure}
\end{mathbsp}

\section{Stochastische Modellierung}
In diesem Abschnitt werden wir erläutern, wie man stochastische Einflüsse, insbesondere zufällige Koeffizienten $\alpha$ und $\beta$, auf die KGG darstellen kann. Die Modellierung, die hier gezeigt wird ist dabei viel allgemeiner gehalten, als wir sie später verwenden werden. Dies entspricht dem praktischen Vorgehen in den Anwendungen und motiviert die Verwendung von stochastischer Modellierung bei Differentialgleichungen. In unserem Fall werden wir uns auf Zufallsvektoren mit bekannten Komponentenverteilungen beschränken.
\subsection{Grundbegriffe}
Wir geben keine Einführung in die klassische Wahrscheinlichkeitstheorie, werden aber die relevanten Begriffe und Definitionen an dieser Stelle kurz wiederholen. Es sei angemerkt, dass neben den vorgestellten stetigen Verteilungen auch diskrete Verteilungen wie die Poisson-Verteilung existieren und sich durch dieselbe Theorie beschreiben lassen. Um die Notation zu vereinfachen, werden wir jedoch ausschließlich stetige Verteilungen betrachten.

\begin{mathdef}[Wahrscheinlichkeitsraum]
Ein Wahrscheinlichkeitsraum $(\Omega,\mathcal{F},P)$ ist ein Tripel bestehend aus 
\begin{itemize}
\item der abzählbaren nichtleeren Ergebnismenge $\Omega$
\item der $\sigma$-Algebra der Ereignisse $\mathcal{F}$ über der Grundmenge $\Omega$
\item dem Wahrscheinlichkeitsmaß $P\colon\mathcal{F}\to [0,1]$
\end{itemize}
\end{mathdef}

\begin{mathdef}[Verteilungsfunktion]
Die Verteilungsfunktion $F_Y$ der Zufallsvariablen $Y\colon\Omega\to\R$ ist definiert durch
\[F_Y(y)\coloneqq P(Y\le y)=P(\left\lbrace \omega\in\Omega |\: Y(\omega)\le y\right\rbrace),\quad y\in\R.\]
\end{mathdef}
\begin{mathdef}[Dichte einer Verteilung]
Existiert zu der Verteilungsfunktion $F_Y$ der Zufallsvariablen $Y\colon\R\to\R$ eine Funktion $\rho_Y\colon\R\to\R_{\ge 0}$ mit
\[F_Y(y)=\int_{-\infty}^y\rho_Y(z)dz,\quad y\in\R\]
so nennen wir diese die Dichte von $F_Y$.\\
Für stetige Zufallsvariablen folgt die Existenz aus dem Satz von Radon-Nikodým.
\end{mathdef}
\begin{mathdef}[Stochastische Unabhängigkeit]
Ist $(\Omega,\mathcal{F},P)$ ein Wahrscheinlichkeitsraum und $Y_1, Y_2\colon \Omega\to\R$ zwei reelle Zufallsvariablen, so nennt man $Y_1$ und $Y_2$ (stochastisch) unabhängig genau dann wenn
\[P(Y_1\in B_1,Y_2\in B_2)=P(Y_1\in B_1)P(Y_2\in B_2)\]
für alle $B_1,B_2\in \mathcal{B}(\R)$, der Borelschen $\sigma$-Algebra über $\R$.
\end{mathdef}
\begin{mathbsp}
Ist $\mathcal{N}(\mu, \sigma^2)$ die Normalverteilung mit Parametern $\mu\in\R$ und $\sigma^2>0$ so gilt für ihre Dichtefunktion
\[\rho_Y(y)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y-\mu)^2}{2\sigma^2}},\quad y\in\R\,.\]
Ist $\mathcal{U}(a,b)$ die Gleichverteilung auf $(a,b)$ so gilt für ihre Dichtefunktion
\[\rho_Y(y)=\begin{cases}\frac{1}{b-a},\quad &y\in (a,b)\\ 0, \quad &\text{sonst}\,. \end{cases}\]
\end{mathbsp}
Folgende Definitionen werden die später hauptsächlich untersuchten Eigenschaften von zufallsabhängigen Größen darstellen.
\begin{mathdef}[Erwartungswert und Varianz]
Ist $Y\colon\R\to\R$ eine reelle Zufallsvariable mit Dichte $\rho_Y$ so definieren wir den Erwartungswert von $Y$ als
\[\mu_Y=\E[Y]=\int_{-\infty}^\infty y\rho_Y(y)dy\]
und die Varianz von $Y$ als 
\[\sigma_Y^2=\text{var}(Y)=\int_{-\infty}^\infty (y-\mu_Y)^2\rho_Y(y)dy=\E[Y^2]-\E[Y]^2.\]
\end{mathdef}
Ohne Beweis präsentieren wir die Inversionsmethode. Diese ist nützlich um aus Zufallsvariablen einer bestimmten Verteilung Zufallsvariablen einer anderen Verteilung zu gewinnen. In der Numerik ist dies ist essentiell für die Erzeugung von Pseudozufallszahlen von beliebigen Verteilungen. Die Methode ist aber auch wichtig für die "`stochastische Normierung"' von verschiedenen Zufallsvariablen zu einem gemeinsamen Wahrscheinlichkeitsraum, auf dem dann Erwartungswerte berechnet werden können.
\begin{maththeorem}[Inversionsmethode]
\label{thinversionsmethode}
Ist $Y$ eine reelle Zufallsvariable mit Verteilungsfunktion $F_Y$, so definieren wir deren Quantilfunktion als
\[F_Y^{-1}(p)\coloneqq \inf\lbrace y\in\R |\: F_Y(y)\ge p\rbrace,\quad p\in\R.\]
Dann gilt
\begin{itemize}
\item $z\le F_Y(y)\iff F_Y^{-1}(z)\le y$\\
\item Falls $Z$ gleichverteilt in $(0,1)$ ist, dann hat $F_Y^{-1}(Z)$ die Verteilungsfunktion $F_Y$. 
\end{itemize}
\end{maththeorem}
Der auch \emph{Gesetz der großen Zahlen} genannte Zentrale Grenzwertsatz bildet die Grundlage für das erste Verfahren zur Berechnung von Erwartungswert und Varianz.
\begin{maththeorem}[Zentraler Grenzwertsatz]
\label{thzentralgrenzwert}
Seien $Y_1,Y_2,\dots,Y_n$ unabhängige und identisch verteilte Zufallsvariablen mit $\E[Y_i]=\mu$ und $\text{var}(Y_i)=\sigma^2<\infty$ Der Mittelwert sei definiert als
\[\overline{Y}\coloneqq \frac{1}{n}\sum_{i=1}^nY_i\]
und linear transformiert durch
\[Z_n=\sqrt{n}\left(\frac{\overline{Y}-\mu}{\sigma}\right).\]
Dann konvergiert für $n\to\infty$ die Verteilungsfunktion von $Z_n$ zu einer $\mathcal{N}(0,1)$ verteilten Verteilungsfunktion.
\end{maththeorem}
\begin{mathdef}[Zufallsvektoren]
Wir nennen $Y=(Y_1,\dots,Y_n)$ einen $n$-dimensionalen Zufallsvektor (häufig auch einfach $n$-dimensionale Zufallsvariable), wenn die Komponenten $Y_1,\dots,Y_n\colon\Omega\to\R$ eindimensionale reelle Zufallsvariablen sind. Sind die Komponenten $Y_i$ stochastisch unabhängig und besitzt jede Komponente $Y_i$ eine Dichte $\rho_{Y_i}$, so gilt die wichtige Darstellung der gemeinsamen Dichtefunktion $\rho_Y$
\[\rho_Y=\prod_{i=1}^n \rho_{Y_i}\]
und die Verteilungsfunktion lässt sich darstellen als
\[F_Y(y_1,\dots,y_n)=\int_{-\infty}^{y_1}\dots\int_{-\infty}^{y_n}\rho_Y(z_1,\dots,z_n)dy_1\dots dy_n.\]
\end{mathdef}

\subsection{Endliche Parametrisierung}
\label{secfiniteparam}
Dieser Abschnitt beschäftigt sich mit der Frage, wie man, ausgehend von einem potentiell unendlich-dimensionalen Wahrscheinlichkeitsraum, eine endliche Approximation desselben erhalten kann. Diese Approximation soll in der Form von $n$ stochastisch unabhängigen Zufallsvariablen vorliegen, welche zu einem $n$"=dimensionalen Zufallsvektor zusammen gefasst werden. Die Bedingung der Unabhängigkeit ist dabei theoretisch zwar wenig einschränkend, aber eine sehr wichtige Grundlage für viele praktische numerische Verfahren.\\
Im Fall unserer stochastischer Klein-Gordon-Gleichung steckt die Zufallsabhängigkeit direkt in den Modellparametern $\alpha$ und $\beta$ und in den Anfangswerten. Auch wenn die Zufallsabhängigkeit wie in diesem Fall direkt im Modell gegeben ist, muss für numerische Lösungsverfahren eine Charakterisierung derselben durch endlich viele unabhängige Zufallsvariablen mit bekannter Verteilung sicher gestellt werden.\\
Wir werden später stets davon ausgehen, dass bereits eine endliche Parametrisierung durch unabhängige Zufallsvariablen mit bekannter Verteilung vorliegt. Der Vollständigkeit halber seien hier kurz Methoden genannt, um das Parametrisierungsproblem zu lösen. Man beachte jedoch, dass einige der Methoden numerisch nicht umsetzbar oder ad-hoc-Lösungen sind, die spezielle Annahmen benötigen. Dieser Abschnitt wurde aus \autocite[Kapitel 4.1+4.2]{dongbinxiu2010} übernommen, wo auch Visualisierungen und kleine Beispiele zu finden sind.

\subsubsection{Unabhängigkeit von endlich vielen Parametern}
Wenn die Zufallsabhängigkeit des Modells bereits durch endlich viele Modellparameter vorliegt, ist die Parameterisierung auf natürliche Art gegeben. Wichtig ist dann, die unabhängigen Parameter zu identifizieren bzw. die Abhängigkeit zu konkretisieren.\\
Für normalverteilte Parameter ist dies auch auf einfache Weise möglich:
\begin{maththeorem}
\label{thgaussunabhg}
Sei $Z\sim\mathcal{N}(0,I_n)$, wobei $I_n$ die n-dimensionale Einheitsmatrix ist, ein unkorrelierter Zufallsvektor. Für die Gaussverteilung ist Unkorreliertheit äquivalent zu Unabhängigkeit und die Komponenten von $Z$ sind somit unabhängig. Sei $A\in\R^{n\times n}$ eine reguläre untere Dreiecksmatrix. Dann gilt:
\[Y\coloneqq AZ\sim\mathcal{N}(0,AA^T)\]
Da die Kovarianzmatrix $C\in\R^{n\times n}$ eines $\mathcal{N}(0,C)$ verteilten Zufallsvektors $Y$ symmetrisch und positiv definit ist, existiert die Cholesky-Zerlegung $C=AA^T$ mit einer regulären unteren Dreicksmatrix $A$. Folglich kann $Y$ durch stochastisch unabhängige Parameter $Z_1,\dots,Z_n$ dargestellt werden.
\end{maththeorem}
Sind die Parameter nicht normalverteilt, so wird das Problem deutlich schwieriger und bis jetzt gibt es keine zufriedenstellende numerische Transformation, die entsprechendes zu Satz \ref{thgaussunabhg} leistet. Eine theoretische Möglichkeit bietet sich jedoch über die Rosenblatt-Transformation, welche auf den in der Praxis selten bekannten bedingten Wahrscheinlichkeiten basiert.

\subsubsection{Parametrisierung von Zufallsprozessen}
Häufig sind die Zufallsabhängigkeiten des Modells nur durch Beobachtungen oder Messungen von Zufallsvariablen möglich. Wir schreiben diese als stochastischen Prozess $(Y_t,t\in T)$, wobei $T$ die Indexmenge ist und $Y_t$ die beobachteten Zufallsvariablen. Wir suchen dann eine Transformation $R$, welche die Darstellung $Y_t=R(Z)$ mit Zufallsvektor $Z=(Z_1,\dots,Z_n)$ und unabhängigen Komponenten $Z_i$ erlaubt. Da $T$ potentiell ein unendlich-dimensionaler Raum ist, kann diese Transformation nicht exakt sein und wir suchen nun eine in einem gewissen Sinne bestmögliche Approximation.\\
Die am häufigsten verwendete Technik ist dabei die Karhunen-Loeve-Darstellung.
\begin{mathdef}[Karhunen-Loeve-Darstellung]
Sei $\mu_Y(t)$ der Erwartungswert des Prozesses $Y_t$ am Punkt $t$ und sei $C(t,s)=\text{cov}(Y_t,Y_s)$ die Kovarianzfunktion. Dann ist die Karhunen-Loeve-Darstellung definiert als
\[Y_t(\omega)=\mu_Y(t)+\sum_{i=1}^\infty \sqrt{\lambda_i}\Psi_i(t)Z_i(\omega)\] wobei $\Psi_i$ die orthogonalen Eigenfunktionen und $\lambda_i$ die zugehörigen Eigenwerte des Eigenwertproblems
\[\int_T C(t,s)\Psi_i(s)ds=\lambda_i\Psi_i(t),\quad t\in T\]
sind. Die paarweise unkorrelierten Zufallsvariablen $Z_i(\omega)$ erfüllen
\[\E[Z_i]=0,\quad \E[Z_iZ_j]=\delta_{ij}\]
und sind definiert durch
\[Z_i(\omega)=\frac{1}{\sqrt{\lambda_i}}\int_T (Y_t(\omega)-\mu_Y(t))\Psi_i(t)dt.\]
Um eine Approximation zu erhalten wird die Reihe bei einem gewissen Index $n\in\N$ abgebrochen.
\end{mathdef}
Wiederrum erhält man daraus für normalverteilte Prozesse eine endliche Menge von unabhängigen Zufallsvariablen. Für nicht-normalverteilte Prozesse wird häufig dennoch die Karhunen-Loeve-Darstellung verwendet und zusätzlich angenommen, dass die $Z_i$ unabhängig sind. Diese Vorgehensweise ist nicht sehr zufriedenstellend und ein offenes Forschungsproblem.

\subsection{Formulierung der stochastischen Klein-Gordon-Gleichung}
In Analogie zur Klein-Gordon-Gleichung (\ref{kgg}) definieren wir für einen Wahrscheinlichkeitsraum $(\Omega,\mathcal{F},P)$ und $Y\colon\Omega\to\R^N$ die stochastische Klein-Gordon-Gleichung (sKGG) für $y=Y(\omega)$ durch
\begin{align}
\label{skgg}
\dtt{u}(t,x,y)&=\alpha(y) \Laplace u(t,x,y) - \beta(x,\omega)u(t,x,y), \: t>0, \, x\in \Torus^d\\
u(0,x,y)&=u_0(x,y), \: x\in \Torus^d\\
\dt{u}(0,x,y)&=v_0(x,y), \: x\in \Torus^d.
\end{align}
Die Lösung \[u(t,x,y)\colon [0,T]\times\Torus^d\times \R^N\to\R\] ist folglich eine zufallsabhängige Größe.\\
Dabei ist die grundlegende Annahme, dass (\ref{skgg}) $P$-fast-sicher wohl gestellt ist, d.h. die Menge an Punkten $\omega$, für welche die partielle Differentialgleichung mit fixem $y=Y(\omega)$ keine eindeutige Lösung besitzt, ist eine Nullmenge bezüglich des Wahrscheinlichkeitmaßes $P$.\\
Wie bereits in Kapitel \ref{secfiniteparam} diskutiert, werden wir stets annehmen, dass die Komponenten $Y_i$ von $Y$ stochastisch unabhängige Zufallsvariablen mit bekannter Verteilung sind.
\begin{mathbsp}
\label{bsp:trial1}
Sei $Y=(Y_1)$ eine eindimensionale und in $(2,3)$ gleichverteilte Zufallsvariable. Dann gilt für $t>0$, $d\in\N$, $x=(x_1,\dots$, $x_d)\in\Torus^d$, $\hat{x}\coloneqq \sum_{i=1}^d x_i$, $y=Y(\omega)$ und Anfangswerten $u_0(x,y)=2\sin(\hat{x})$, $v_0(x,y)\equiv 0:$
\begin{equation*}
u(t,x,y)=2\cos(ty)\sin(\hat{x})
\end{equation*}
löst die stochastische KGG (\ref{skgg}) für $\alpha(y)=\frac{y}{d}$ und $\beta(x,y)=y^2-y$. Diese Parameter und Anfangswerte entsprechen der \nameref{trial:1} im Anhang, dort finden sich auch weitere untersuchte Konfigurationen auf die in Zukunft verwiesen wird. Die Vorgehensweise zum Erhalt von Referenzlösungen bzw. Referenzapproximationen wird dort ausführlich erläutert.\\
Für den Erwartungswert und die Varianz von $u$ gelten
\begin{align*}
\E[u(t,x,Y)]&=\int_2^3u(t,x,y)dy=\frac{2}{t}\sin(\hat{x})(\sin(3t) - \sin(2t))\\
\text{var}(u(t,x,Y))&=\frac{1}{t}\sin^2(\hat{x})\left(2t + \sin(6t) - \sin(4t)\right)- \left(\frac{2}{t}\sin(\hat{x})(\sin(3t) - \sin(2t))\right)^2.
\end{align*}
Um einen potentiellen Denkfehler zu vermeiden, weisen wir an dieser Stelle explizit darauf hin, dass 
\[\E[u(t,x,Y)]=\frac{2}{t}\sin(\hat{x})(\sin(3t) - \sin(2t))\quad \neq \quad 2\sin(\hat{x})\cos(\frac{5}{2}t)=u(t,x,\E[Y]).\]
Dies erkennt man beispielsweise am Zeitpunkt $t=\frac{\pi}{2}$, wo gilt
\[\E[u(t,x,Y)]=-\sin(\hat{x})\pi \neq -\sin(\hat{x})\sqrt{2}=u(t,x,\E[Y]).\]
Der Erwartungswert ist linear, die Abhängigkeiten von $y$ sind es aber nicht. Diese erste fehlgeschlagene Idee, den Erwartungswert durch das Lösen eines deterministischen Systems zu erhalten, ist jedoch nicht vollends vergebens. Wir werden am Beispiel der Monte-Carlo-Methode sehen, dass wir dazu allerdings weit mehr als ein deterministisches System lösen müssen.
\end{mathbsp}

